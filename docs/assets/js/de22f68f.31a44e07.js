"use strict";(self.webpackChunknew_nav_docusaurus_2_2=self.webpackChunknew_nav_docusaurus_2_2||[]).push([[18396],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},m=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=d(a),u=i,h=c["".concat(l,".").concat(u)]||c[u]||p[u]||r;return a?n.createElement(h,s(s({ref:t},m),{},{components:a})):n.createElement(h,s({ref:t},m))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,s=new Array(r);s[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[c]="string"==typeof e?e:i,s[1]=o;for(var d=2;d<r;d++)s[d]=a[d];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},22759:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var n=a(87462),i=(a(67294),a(3905));const r={sidebar_label:"dbt",slug:"/en/integrations/dbt",sidebar_position:1,description:"Users can transform and model their data in ClickHouse using dbt"},s="Integrating dbt and ClickHouse",o={unversionedId:"en/integrations/data-ingestion/etl-tools/dbt/index",id:"en/integrations/data-ingestion/etl-tools/dbt/index",title:"Integrating dbt and ClickHouse",description:"Users can transform and model their data in ClickHouse using dbt",source:"@site/docs/en/integrations/data-ingestion/etl-tools/dbt/index.md",sourceDirName:"en/integrations/data-ingestion/etl-tools/dbt",slug:"/en/integrations/dbt",permalink:"/docs/en/integrations/dbt",draft:!1,editUrl:"https://github.com/ClickHouse/clickhouse-docs/blob/main/docs/en/integrations/data-ingestion/etl-tools/dbt/index.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_label:"dbt",slug:"/en/integrations/dbt",sidebar_position:1,description:"Users can transform and model their data in ClickHouse using dbt"},sidebar:"docs",previous:{title:"Kafka",permalink:"/docs/en/integrations/kafka/"},next:{title:"Redshift",permalink:"/docs/en/integrations/redshift"}},l={},d=[{value:"Concepts",id:"concepts",level:2},{value:"Setup of dbt and the ClickHouse plugin",id:"setup-of-dbt-and-the-clickhouse-plugin",level:2},{value:"dbt",id:"dbt",level:3},{value:"ClickHouse plugin",id:"clickhouse-plugin",level:3},{value:"Prepare ClickHouse",id:"prepare-clickhouse",level:3},{value:"Connecting to ClickHouse",id:"connecting-to-clickhouse",level:2},{value:"Creating a Simple View Materialization",id:"creating-a-simple-view-materialization",level:2},{value:"Creating a Table Materialization",id:"creating-a-table-materialization",level:2},{value:"Creating an Incremental Materialization",id:"creating-an-incremental-materialization",level:2},{value:"Internals",id:"internals",level:3},{value:"Append Strategy (inserts-only mode)",id:"append-strategy-inserts-only-mode",level:3},{value:"Delete+Insert mode (Experimental)",id:"deleteinsert-mode-experimental",level:3},{value:"Creating a Snapshot",id:"creating-a-snapshot",level:2},{value:"Using Seeds",id:"using-seeds",level:2},{value:"Limitations",id:"limitations",level:2}],m={toc:d},c="wrapper";function p(e){let{components:t,...r}=e;return(0,i.kt)(c,(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"integrating-dbt-and-clickhouse"},"Integrating dbt and ClickHouse"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"dbt")," (data build tool) enables analytics engineers to transform data in their warehouses by simply writing select statements. dbt handles materializing these select statements into objects in the database in the form of tables and views - performing the T of ",(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Extract,_load,_transform"},"Extract Load and Transform (ELT)"),". Users can create a model defined by a SELECT statement."),(0,i.kt)("p",null,"Within dbt, these models can be cross-referenced and layered to allow the construction of higher-level concepts. The boilerplate SQL required to connect models is automatically generated. Furthermore, dbt identifies dependencies between models and ensures they are created in the appropriate order using a directed acyclic graph (DAG)."),(0,i.kt)("p",null,"Dbt is compatible with ClickHouse through a ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/ClickHouse/dbt-clickhouse"},"ClickHouse-supported plugin"),". We describe the process for connecting ClickHouse with a simple example based on a publicly available IMDB dataset. We additionally highlight some of the limitations of the current connector."),(0,i.kt)("h2",{id:"concepts"},"Concepts"),(0,i.kt)("p",null,"dbt introduces the concept of a model. This is defined as a SQL statement, potentially joining many tables. A model can be \u201cmaterialized\u201d in a number of ways. A materialization represents a build strategy for the model\u2019s select query. The code behind a materialization is boilerplate SQL that wraps your SELECT query in a statement in order to create a new or update an existing relation."),(0,i.kt)("p",null,"dbt provides 4 types of materialization:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"view")," (default): The model is built as a view in the database."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"table"),": The model is built as a table in the database."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"ephemeral"),": The model is not directly built in the database but is instead pulled into dependent models as common table expressions."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"incremental"),": The model is initially materialized as a table, and in subsequent runs, dbt inserts new rows and updates changed rows in the table.")),(0,i.kt)("p",null,"Additional syntax and clauses define how these models should be updated if their underlying data changes. dbt generally recommends starting with the view materialization until performance becomes a concern. The table materialization provides a query time performance improvement by capturing the results of the model\u2019s query as a table at the expense of increased storage. The incremental approach builds on this further to allow subsequent updates to the underlying data to be captured in the target table."),(0,i.kt)("p",null,"The",(0,i.kt)("a",{parentName:"p",href:"https://github.com/silentsokolov/dbt-clickhouse"}," current plugin")," for ClickHouse supports the ",(0,i.kt)("strong",{parentName:"p"},"view"),", ",(0,i.kt)("strong",{parentName:"p"},"table,")," and ",(0,i.kt)("strong",{parentName:"p"},"incremental")," materializations. Ephemeral is not supported. The plugin also supports dbt",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/building-a-dbt-project/snapshots#check-strategy"}," snapshots")," and",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/building-a-dbt-project/seeds"}," seeds")," which we explore in this guide."),(0,i.kt)("p",null,"For the following guides, we assume you have a ClickHouse instance available."),(0,i.kt)("h2",{id:"setup-of-dbt-and-the-clickhouse-plugin"},"Setup of dbt and the ClickHouse plugin"),(0,i.kt)("h3",{id:"dbt"},"dbt"),(0,i.kt)("p",null,"We assume the use of the dbt CLI for the following examples. Users may also wish to consider",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/dbt-cloud/cloud-overview"}," dbt Cloud"),", which offers a web-based Integrated Development Environment (IDE) allowing users to edit and run projects."),(0,i.kt)("p",null,"dbt offers a number of options for CLI installation. Follow the instructions described",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/dbt-cli/install/overview"}," here"),". At this stage install dbt-core only. We recommend the use of ",(0,i.kt)("inlineCode",{parentName:"p"},"pip"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install dbt-core\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Important: The following is tested under python 3.9.")),(0,i.kt)("h3",{id:"clickhouse-plugin"},"ClickHouse plugin"),(0,i.kt)("p",null,"Install the dbt ClickHouse plugin:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install dbt-clickhouse\n")),(0,i.kt)("h3",{id:"prepare-clickhouse"},"Prepare ClickHouse"),(0,i.kt)("p",null,"dbt excels when modeling highly relational data. For the purposes of example, we provide a small IMDB dataset with the following relational schema. This dataset originates from the",(0,i.kt)("a",{parentName:"p",href:"https://relational.fit.cvut.cz/dataset/IMDb"}," relational dataset repository"),". This is trivial relative to common schemas used with dbt but represents a manageable sample:"),(0,i.kt)("img",{src:a(97988).Z,class:"image",alt:"IMDB table schema",style:{width:"100%"}}),(0,i.kt)("p",null,"We use a subset of these tables as shown."),(0,i.kt)("p",null,"Create the following tables:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE DATABASE imdb;\n\nCREATE TABLE imdb.actors\n(\n    id         UInt32,\n    first_name String,\n    last_name  String,\n    gender     FixedString(1)\n) ENGINE = MergeTree ORDER BY (id, first_name, last_name, gender);\n\nCREATE TABLE imdb.directors\n(\n    id         UInt32,\n    first_name String,\n    last_name  String\n) ENGINE = MergeTree ORDER BY (id, first_name, last_name);\n\nCREATE TABLE imdb.genres\n(\n    movie_id UInt32,\n    genre    String\n) ENGINE = MergeTree ORDER BY (movie_id, genre);\n\nCREATE TABLE imdb.movie_directors\n(\n    director_id UInt32,\n    movie_id    UInt64\n) ENGINE = MergeTree ORDER BY (director_id, movie_id);\n\nCREATE TABLE imdb.movies\n(\n    id   UInt32,\n    name String,\n    year UInt32,\n    rank Float32 DEFAULT 0\n) ENGINE = MergeTree ORDER BY (id, name, year);\n\nCREATE TABLE imdb.roles\n(\n    created_at DateTime DEFAULT now(),\n    actor_id   UInt32,\n    movie_id   UInt32,\n    role       String\n) ENGINE = MergeTree ORDER BY (actor_id, movie_id);\n")),(0,i.kt)("admonition",{type:"note"},(0,i.kt)("p",{parentName:"admonition"},"The column ",(0,i.kt)("inlineCode",{parentName:"p"},"created_at")," for the table ",(0,i.kt)("inlineCode",{parentName:"p"},"roles"),", which defaults to a value of ",(0,i.kt)("inlineCode",{parentName:"p"},"now()"),". We use this later to identify incremental updates to our models - see ",(0,i.kt)("a",{parentName:"p",href:"#creating-an-incremental-materialization"},"Incremental Models"),".")),(0,i.kt)("p",null,"We use the ",(0,i.kt)("inlineCode",{parentName:"p"},"s3")," function to read the source data from public endpoints to insert data. Run the following commands to populate the tables:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.actors\nSELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_actors.tsv.gz',\n'TSVWithNames');\n\nINSERT INTO imdb.directors\nSELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_directors.tsv.gz',\n'TSVWithNames');\n\nINSERT INTO imdb.genres\nSELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_movies_genres.tsv.gz',\n'TSVWithNames');\n\nINSERT INTO imdb.movie_directors\nSELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_movies_directors.tsv.gz',\n        'TSVWithNames');\n\nINSERT INTO imdb.movies\nSELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_movies.tsv.gz',\n'TSVWithNames');\n\nINSERT INTO imdb.roles(actor_id, movie_id, role)\nSELECT actor_id, movie_id, role\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/imdb/imdb_ijs_roles.tsv.gz',\n'TSVWithNames');\n")),(0,i.kt)("p",null,"The execution of these may vary depending on your bandwidth, but each should only take a few seconds to complete. Execute the following query to compute a summary of each actor, ordered by the most movie appearances, and to confirm the data was loaded successfully:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT id,\n       any(actor_name)          as name,\n       uniqExact(movie_id)    as num_movies,\n       avg(rank)                as avg_rank,\n       uniqExact(genre)         as unique_genres,\n       uniqExact(director_name) as uniq_directors,\n       max(created_at)          as updated_at\nFROM (\n         SELECT imdb.actors.id  as id,\n                concat(imdb.actors.first_name, ' ', imdb.actors.last_name)  as actor_name,\n                imdb.movies.id as movie_id,\n                imdb.movies.rank as rank,\n                genre,\n                concat(imdb.directors.first_name, ' ', imdb.directors.last_name) as director_name,\n                created_at\n         FROM imdb.actors\n                  JOIN imdb.roles ON imdb.roles.actor_id = imdb.actors.id\n                  LEFT OUTER JOIN imdb.movies ON imdb.movies.id = imdb.roles.movie_id\n                  LEFT OUTER JOIN imdb.genres ON imdb.genres.movie_id = imdb.movies.id\n                  LEFT OUTER JOIN imdb.movie_directors ON imdb.movie_directors.movie_id = imdb.movies.id\n                  LEFT OUTER JOIN imdb.directors ON imdb.directors.id = imdb.movie_directors.director_id\n         )\nGROUP BY id\nORDER BY num_movies DESC\nLIMIT 5;\n")),(0,i.kt)("p",null,"The response should look like:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+------------+----------+------------------+-------------+--------------+-------------------+\n|id    |name        |num_movies|avg_rank          |unique_genres|uniq_directors|updated_at         |\n+------+------------+----------+------------------+-------------+--------------+-------------------+\n|45332 |Mel Blanc   |832       |6.175853582979779 |18           |84            |2022-04-26 14:01:45|\n|621468|Bess Flowers|659       |5.57727638854796  |19           |293           |2022-04-26 14:01:46|\n|372839|Lee Phelps  |527       |5.032976449684617 |18           |261           |2022-04-26 14:01:46|\n|283127|Tom London  |525       |2.8721716524875673|17           |203           |2022-04-26 14:01:46|\n|356804|Bud Osborne |515       |2.0389507108727773|15           |149           |2022-04-26 14:01:46|\n+------+------------+----------+------------------+-------------+--------------+-------------------+\n")),(0,i.kt)("p",null,"In the later guides, we will convert this query into a model - materializing it in ClickHouse as a dbt view and table."),(0,i.kt)("h2",{id:"connecting-to-clickhouse"},"Connecting to ClickHouse"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create a dbt project. In this case we name this after our imdb source. When prompted, select ",(0,i.kt)("inlineCode",{parentName:"p"},"clickhouse")," as the database source."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'clickhouse-user@clickhouse:~$ dbt init imdb\n\n16:52:40  Running with dbt=1.1.0\nWhich database would you like to use?\n[1] clickhouse\n\n(Don\'t see the one you want? https://docs.getdbt.com/docs/available-adapters)\n\nEnter a number: 1\n16:53:21  No sample profile found for clickhouse.\n16:53:21\nYour new dbt project "imdb" was created!\n\nFor more information on how to configure the profiles.yml file,\nplease consult the dbt documentation here:\n\nhttps://docs.getdbt.com/docs/configure-your-profile\n'))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"cd")," into your project folder:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cd imdb\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"At this point, you will need the text editor of your choice. In the examples below, we use the popular VSCode. Opening the IMDB directory, you should see a collection of yml and sql files:"),(0,i.kt)("img",{src:a(60897).Z,class:"image",alt:"New dbt project",style:{width:"100%"}})),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Update your ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt_project.yml")," file to specify our first model - ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary")," and set profile to ",(0,i.kt)("inlineCode",{parentName:"p"},"clickhouse_imdb"),"."),(0,i.kt)("img",{src:a(44604).Z,class:"image",alt:"dbt profile",style:{width:"100%"}}),(0,i.kt)("img",{src:a(39232).Z,class:"image",alt:"dbt profile",style:{width:"100%"}})),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"We next need to provide dbt with the connection details for our ClickHouse instance. Add the following to your ",(0,i.kt)("inlineCode",{parentName:"p"},"~/.dbt/profiles.yml"),"."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-yml"},"clickhouse_imdb:\n  target: dev\n  outputs:\n    dev:\n      type: clickhouse\n      schema: imdb_dbt\n      host: localhost\n      port: 8123\n      user: default\n      password: ''\n      secure: False\n")),(0,i.kt)("p",{parentName:"li"},"Note the need to modify the user and password. There are additional available settings documented",(0,i.kt)("a",{parentName:"p",href:"https://github.com/silentsokolov/dbt-clickhouse#example-profile"}," here"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"From the IMDB directory, execute the ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt debug")," command to confirm whether dbt is able to connect to ClickHouse."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ dbt debug\n17:33:53  Running with dbt=1.1.0\ndbt version: 1.1.0\npython version: 3.10.1\npython path: /home/dale/.pyenv/versions/3.10.1/bin/python3.10\nos info: Linux-5.13.0-10039-tuxedo-x86_64-with-glibc2.31\nUsing profiles.yml file at /home/dale/.dbt/profiles.yml\nUsing dbt_project.yml file at /opt/dbt/imdb/dbt_project.yml\n\nConfiguration:\nprofiles.yml file [OK found and valid]\ndbt_project.yml file [OK found and valid]\n\nRequired dependencies:\n- git [OK found]\n\nConnection:\nhost: localhost\nport: 8123\nuser: default\nschema: imdb_dbt\nsecure: False\nverify: False\nConnection test: [OK connection ok]\n\nAll checks passed!\n")),(0,i.kt)("p",{parentName:"li"},"Confirm the response includes ",(0,i.kt)("inlineCode",{parentName:"p"},"Connection test: [OK connection ok]")," indicating a successful connection."))),(0,i.kt)("h2",{id:"creating-a-simple-view-materialization"},"Creating a Simple View Materialization"),(0,i.kt)("p",null,"When using the view materialization, a model is rebuilt as a view on each run, via a ",(0,i.kt)("inlineCode",{parentName:"p"},"CREATE VIEW AS")," statement in ClickHouse. This doesn't require any additional storage of data but will be slower to query than table materializations."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"From the ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb")," folder, delete the directory ",(0,i.kt)("inlineCode",{parentName:"p"},"models/example"),":"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ rm -rf models/example\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create a new file in the ",(0,i.kt)("inlineCode",{parentName:"p"},"actors")," within the ",(0,i.kt)("inlineCode",{parentName:"p"},"models")," folder. Here we create files that each represent an actor model:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ mkdir models/actors\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create the files ",(0,i.kt)("inlineCode",{parentName:"p"},"schema.yml")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary.sql")," in the ",(0,i.kt)("inlineCode",{parentName:"p"},"models/actors")," folder."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ touch models/actors/actor_summary.sql\nclickhouse-user@clickhouse:~/imdb$ touch models/actors/schema.yml\n")),(0,i.kt)("p",{parentName:"li"},"The file ",(0,i.kt)("inlineCode",{parentName:"p"},"schema.yml")," defines our tables. These will subsequently be available for use in macros.  Edit\n",(0,i.kt)("inlineCode",{parentName:"p"},"models/actors/schema.yml")," to contain this content:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-yml"},"version: 2\n\nsources:\n- name: imdb\n  tables:\n  - name: directors\n  - name: actors\n  - name: roles\n  - name: movies\n  - name: genres\n  - name: movie_directors\n")),(0,i.kt)("p",{parentName:"li"},"The ",(0,i.kt)("inlineCode",{parentName:"p"},"actors_summary.sql")," defines our actual model. Note in the config function we also request the model be materialized as a view in ClickHouse. Our tables are referenced from the ",(0,i.kt)("inlineCode",{parentName:"p"},"schema.yml")," file via the function ",(0,i.kt)("inlineCode",{parentName:"p"},"source")," e.g. ",(0,i.kt)("inlineCode",{parentName:"p"},"source('imdb', 'movies')")," refers to the ",(0,i.kt)("inlineCode",{parentName:"p"},"movies")," table in the ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb")," database.  Edit ",(0,i.kt)("inlineCode",{parentName:"p"},"models/actors/actors_summary.sql")," to contain this content:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(materialized='view') }}\n\nwith actor_summary as (\nSELECT id,\n    any(actor_name) as name,\n    uniqExact(movie_id)    as num_movies,\n    avg(rank)                as avg_rank,\n    uniqExact(genre)         as genres,\n    uniqExact(director_name) as directors,\n    max(created_at) as updated_at\nFROM (\n        SELECT {{ source('imdb', 'actors') }}.id as id,\n                concat({{ source('imdb', 'actors') }}.first_name, ' ', {{ source('imdb', 'actors') }}.last_name) as actor_name,\n                {{ source('imdb', 'movies') }}.id as movie_id,\n                {{ source('imdb', 'movies') }}.rank as rank,\n                genre,\n                concat({{ source('imdb', 'directors') }}.first_name, ' ', {{ source('imdb', 'directors') }}.last_name) as director_name,\n                created_at\n        FROM {{ source('imdb', 'actors') }}\n                    JOIN {{ source('imdb', 'roles') }} ON {{ source('imdb', 'roles') }}.actor_id = {{ source('imdb', 'actors') }}.id\n                    LEFT OUTER JOIN {{ source('imdb', 'movies') }} ON {{ source('imdb', 'movies') }}.id = {{ source('imdb', 'roles') }}.movie_id\n                    LEFT OUTER JOIN {{ source('imdb', 'genres') }} ON {{ source('imdb', 'genres') }}.movie_id = {{ source('imdb', 'movies') }}.id\n                    LEFT OUTER JOIN {{ source('imdb', 'movie_directors') }} ON {{ source('imdb', 'movie_directors') }}.movie_id = {{ source('imdb', 'movies') }}.id\n                    LEFT OUTER JOIN {{ source('imdb', 'directors') }} ON {{ source('imdb', 'directors') }}.id = {{ source('imdb', 'movie_directors') }}.director_id\n        )\nGROUP BY id\n)\n\nselect *\nfrom actor_summary\n")),(0,i.kt)("p",{parentName:"li"},"Note how we include the column ",(0,i.kt)("inlineCode",{parentName:"p"},"updated_at")," in our final actor_summary. We use this later for incremental materializations.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"From the ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb")," directory execute the command ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run"),"."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ dbt run\n15:05:35  Running with dbt=1.1.0\n15:05:35  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n15:05:35\n15:05:36  Concurrency: 1 threads (target='dev')\n15:05:36\n15:05:36  1 of 1 START view model imdb_dbt.actor_summary.................................. [RUN]\n15:05:37  1 of 1 OK created view model imdb_dbt.actor_summary............................. [OK in 1.00s]\n15:05:37\n15:05:37  Finished running 1 view model in 1.97s.\n15:05:37\n15:05:37  Completed successfully\n15:05:37\n15:05:37  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"dbt will represent the model as a view in ClickHouse as requested. We can now query this view directly. This view will have been created in the ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb_dbt")," database - this is determined by the schema parameter in the file ",(0,i.kt)("inlineCode",{parentName:"p"},"~/.dbt/profiles.yml")," under the ",(0,i.kt)("inlineCode",{parentName:"p"},"clickhouse_imdb")," profile."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SHOW DATABASES;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------------------+\n|name              |\n+------------------+\n|INFORMATION_SCHEMA|\n|default           |\n|imdb              |\n|imdb_dbt          |  <---created by dbt!\n|information_schema|\n|system            |\n+------------------+\n")),(0,i.kt)("p",{parentName:"li"},"Querying this view, we can replicate the results of our earlier query with a simpler syntax:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+------------+----------+------------------+------+---------+-------------------+\n|id    |name        |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+------------+----------+------------------+------+---------+-------------------+\n|45332 |Mel Blanc   |832       |6.175853582979779 |18    |84       |2022-04-26 15:26:55|\n|621468|Bess Flowers|659       |5.57727638854796  |19    |293      |2022-04-26 15:26:57|\n|372839|Lee Phelps  |527       |5.032976449684617 |18    |261      |2022-04-26 15:26:56|\n|283127|Tom London  |525       |2.8721716524875673|17    |203      |2022-04-26 15:26:56|\n|356804|Bud Osborne |515       |2.0389507108727773|15    |149      |2022-04-26 15:26:56|\n+------+------------+----------+------------------+------+---------+-------------------+\n")))),(0,i.kt)("h2",{id:"creating-a-table-materialization"},"Creating a Table Materialization"),(0,i.kt)("p",null,"In the previous example, our model was materialized as a view. While this might offer sufficient performance for some queries, more complex SELECTs or frequently executed queries may be better materialized as a table.  This materialization is useful for models that will be queried by BI tools to ensure users have a faster experience. This effectively causes the query results to be stored as a new table, with the associated storage overheads - effectively, an ",(0,i.kt)("inlineCode",{parentName:"p"},"INSERT TO SELECT")," is executed. Note that this table will be reconstructed each time i.e., it is not incremental. Large result sets may therefore result in long execution times - see ",(0,i.kt)("a",{parentName:"p",href:"#limitations"},"dbt Limitations"),"."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Modify the file ",(0,i.kt)("inlineCode",{parentName:"p"},"actors_summary.sql")," such that the ",(0,i.kt)("inlineCode",{parentName:"p"},"materialized")," parameter is set to ",(0,i.kt)("inlineCode",{parentName:"p"},"table"),". Notice how ",(0,i.kt)("inlineCode",{parentName:"p"},"ORDER BY")," is defined, and notice we use the ",(0,i.kt)("inlineCode",{parentName:"p"},"MergeTree")," table engine:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='table') }}\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"From the ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb")," directory execute the command ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run"),". This execution may take a little longer to execute - around 10s on most machines."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ dbt run\n15:13:27  Running with dbt=1.1.0\n15:13:27  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n15:13:27\n15:13:28  Concurrency: 1 threads (target='dev')\n15:13:28\n15:13:28  1 of 1 START table model imdb_dbt.actor_summary................................. [RUN]\n15:13:37  1 of 1 OK created table model imdb_dbt.actor_summary............................ [OK in 9.22s]\n15:13:37\n15:13:37  Finished running 1 table model in 10.20s.\n15:13:37\n15:13:37  Completed successfully\n15:13:37\n15:13:37  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Confirm the creation of the table ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb_dbt.actor_summary"),":"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SHOW CREATE TABLE imdb_dbt.actor_summary;\n")),(0,i.kt)("p",{parentName:"li"},"You should the table with the appropriate data types:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+----------------------------------------\n|statement\n+----------------------------------------\n|CREATE TABLE imdb_dbt.actor_summary\n|(\n|`id` UInt32,\n|`first_name` String,\n|`last_name` String,\n|`num_movies` UInt64,\n|`updated_at` DateTime\n|)\n|ENGINE = MergeTree\n|ORDER BY (id, first_name, last_name)\n|SETTINGS index_granularity = 8192\n+----------------------------------------\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Confirm the results from this table are consistent with previous responses. Notice an appreciable improvement in the response time now that the model is a table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+------------+----------+------------------+------+---------+-------------------+\n|id    |name        |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+------------+----------+------------------+------+---------+-------------------+\n|45332 |Mel Blanc   |832       |6.175853582979779 |18    |84       |2022-04-26 15:26:55|\n|621468|Bess Flowers|659       |5.57727638854796  |19    |293      |2022-04-26 15:26:57|\n|372839|Lee Phelps  |527       |5.032976449684617 |18    |261      |2022-04-26 15:26:56|\n|283127|Tom London  |525       |2.8721716524875673|17    |203      |2022-04-26 15:26:56|\n|356804|Bud Osborne |515       |2.0389507108727773|15    |149      |2022-04-26 15:26:56|\n+------+------------+----------+------------------+------+---------+-------------------+\n")),(0,i.kt)("p",{parentName:"li"},"Feel free to issue other queries against this model. For example, which actors have the highest ranking movies with more than 5 appearances?"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary WHERE num_movies > 5 ORDER BY avg_rank  DESC LIMIT 10;\n")))),(0,i.kt)("h2",{id:"creating-an-incremental-materialization"},"Creating an Incremental Materialization"),(0,i.kt)("p",null,"The previous example created a table to materialize the model. This table will be reconstructed for each dbt execution. This may be infeasible and extremely costly for larger result sets or complex transformations. To address this challenge and reduce the build time, dbt offers Incremental materializations. This allows dbt to insert or update records into a table since the last execution, making it appropriate for event-style data. Under the hood a temporary table is created with all the updated records and then all the untouched records as well as the updated records are inserted into a new target table. This results in similar ",(0,i.kt)("a",{parentName:"p",href:"#limitations"},"limitations")," for large result sets as for the table model."),(0,i.kt)("p",null,"To overcome these limitations for large sets, the plugin supports \u2018inserts_only\u2018 mode, where all the updates are inserted into the target table without creating a temporary table (more about it below)."),(0,i.kt)("p",null,'To illustrate this example, we will add the actor "Clicky McClickHouse", who will appear in an incredible 910 movies - ensuring he has appeared in more films than even ',(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Mel_Blanc"},"Mel Blanc"),"."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"First, we modify our model to be of type incremental. This addition requires:"),(0,i.kt)("ol",{parentName:"li"},(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"unique_key")," - To ensure the plugin can uniquely identify rows, we must provide a unique_key - in this case, the ",(0,i.kt)("inlineCode",{parentName:"li"},"id")," field from our query will suffice. This ensures we will have no row duplicates in our materialized table. For more details on uniqueness constraints, see",(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models#defining-a-uniqueness-constraint-optional"}," here"),"."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Incremental filter")," - We also need to tell dbt how it should identify which rows have changed on an incremental run. This is achieved by providing a delta expression. Typically this involves a timestamp for event data; hence our updated_at timestamp field. This column, which defaults to the value of now() when rows are inserted, allows new roles to be identified. Additionally, we need to identify the alternative case where new actors are added. Using the {{this}} variable, to denote the existing materialized table, this gives us the expression ",(0,i.kt)("inlineCode",{parentName:"li"},"where id > (select max(id) from {{ this }}) or updated_at > (select max(updated_at) from {{this}})"),". We embed this inside the ",(0,i.kt)("inlineCode",{parentName:"li"},"{% if is_incremental() %}")," condition, ensuring it is only used on incremental runs and not when the table is first constructed. For more details on filtering rows for incremental models, see ",(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models#filtering-rows-on-an-incremental-run"},"this discussion in the dbt docs"),".")),(0,i.kt)("p",{parentName:"li"},"Update the file ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary.sql")," as follows:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='incremental', unique_key='id') }}\nwith actor_summary as (\n    SELECT id,\n        any(actor_name) as name,\n        uniqExact(movie_id)    as num_movies,\n        avg(rank)                as avg_rank,\n        uniqExact(genre)         as genres,\n        uniqExact(director_name) as directors,\n        max(created_at) as updated_at\n    FROM (\n        SELECT {{ source('imdb', 'actors') }}.id as id,\n            concat({{ source('imdb', 'actors') }}.first_name, ' ', {{ source('imdb', 'actors') }}.last_name) as actor_name,\n            {{ source('imdb', 'movies') }}.id as movie_id,\n            {{ source('imdb', 'movies') }}.rank as rank,\n            genre,\n            concat({{ source('imdb', 'directors') }}.first_name, ' ', {{ source('imdb', 'directors') }}.last_name) as director_name,\n            created_at\n    FROM {{ source('imdb', 'actors') }}\n        JOIN {{ source('imdb', 'roles') }} ON {{ source('imdb', 'roles') }}.actor_id = {{ source('imdb', 'actors') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'movies') }} ON {{ source('imdb', 'movies') }}.id = {{ source('imdb', 'roles') }}.movie_id\n        LEFT OUTER JOIN {{ source('imdb', 'genres') }} ON {{ source('imdb', 'genres') }}.movie_id = {{ source('imdb', 'movies') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'movie_directors') }} ON {{ source('imdb', 'movie_directors') }}.movie_id = {{ source('imdb', 'movies') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'directors') }} ON {{ source('imdb', 'directors') }}.id = {{ source('imdb', 'movie_directors') }}.director_id\n    )\n    GROUP BY id\n)\nselect *\nfrom actor_summary\n\n{% if is_incremental() %}\n\n-- this filter will only be applied on an incremental run\nwhere id > (select max(id) from {{ this }}) or updated_at > (select max(updated_at) from {{this}})\n\n{% endif %}\n")),(0,i.kt)("p",{parentName:"li"},"Note that our model will only respond to updates and additions to the ",(0,i.kt)("inlineCode",{parentName:"p"},"roles")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"actors")," tables. To respond to all tables, users would be encouraged to split this model into multiple sub-models - each with their own incremental criteria. These models can in turn be referenced and connected. For further details on cross-referencing models see ",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/reference/dbt-jinja-functions/ref"},"here"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute a ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run")," and confirm the results of the resulting table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"clickhouse-user@clickhouse:~/imdb$  dbt run\n15:33:34  Running with dbt=1.1.0\n15:33:34  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n15:33:34\n15:33:35  Concurrency: 1 threads (target='dev')\n15:33:35\n15:33:35  1 of 1 START incremental model imdb_dbt.actor_summary........................... [RUN]\n15:33:41  1 of 1 OK created incremental model imdb_dbt.actor_summary...................... [OK in 6.33s]\n15:33:41\n15:33:41  Finished running 1 incremental model in 7.30s.\n15:33:41\n15:33:41  Completed successfully\n15:33:41\n15:33:41  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+------------+----------+------------------+------+---------+-------------------+\n|id    |name        |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+------------+----------+------------------+------+---------+-------------------+\n|45332 |Mel Blanc   |832       |6.175853582979779 |18    |84       |2022-04-26 15:26:55|\n|621468|Bess Flowers|659       |5.57727638854796  |19    |293      |2022-04-26 15:26:57|\n|372839|Lee Phelps  |527       |5.032976449684617 |18    |261      |2022-04-26 15:26:56|\n|283127|Tom London  |525       |2.8721716524875673|17    |203      |2022-04-26 15:26:56|\n|356804|Bud Osborne |515       |2.0389507108727773|15    |149      |2022-04-26 15:26:56|\n+------+------------+----------+------------------+------+---------+-------------------+\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},'We will now add data to our model to illustrate an incremental update. Add our actor  "Clicky McClickHouse" to the ',(0,i.kt)("inlineCode",{parentName:"p"},"actors")," table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.actors VALUES (845466, 'Clicky', 'McClickHouse', 'M');\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Let's have Clicky star in 910 random movies:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.roles\nSELECT now() as created_at, 845466 as actor_id, id as movie_id, 'Himself' as role\nFROM imdb.movies\nLIMIT 910 OFFSET 10000;\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Confirm he is indeed now the actor with the most appearances by querying the underlying source table and bypassing any dbt models:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT id,\n    any(actor_name)          as name,\n    uniqExact(movie_id)    as num_movies,\n    avg(rank)                as avg_rank,\n    uniqExact(genre)         as unique_genres,\n    uniqExact(director_name) as uniq_directors,\n    max(created_at)          as updated_at\nFROM (\n        SELECT imdb.actors.id                                                   as id,\n                concat(imdb.actors.first_name, ' ', imdb.actors.last_name)       as actor_name,\n                imdb.movies.id as movie_id,\n                imdb.movies.rank                                                 as rank,\n                genre,\n                concat(imdb.directors.first_name, ' ', imdb.directors.last_name) as director_name,\n                created_at\n        FROM imdb.actors\n                JOIN imdb.roles ON imdb.roles.actor_id = imdb.actors.id\n                LEFT OUTER JOIN imdb.movies ON imdb.movies.id = imdb.roles.movie_id\n                LEFT OUTER JOIN imdb.genres ON imdb.genres.movie_id = imdb.movies.id\n                LEFT OUTER JOIN imdb.movie_directors ON imdb.movie_directors.movie_id = imdb.movies.id\n                LEFT OUTER JOIN imdb.directors ON imdb.directors.id = imdb.movie_directors.director_id\n        )\nGROUP BY id\nORDER BY num_movies DESC\nLIMIT 2;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+-------------------+----------+------------------+------+---------+-------------------+\n|id    |name               |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+-------------------+----------+------------------+------+---------+-------------------+\n|845466|Clicky McClickHouse|910       |1.4687938697032283|21    |662      |2022-04-26 16:20:36|\n|45332 |Mel Blanc          |909       |5.7884792542982515|19    |148      |2022-04-26 16:17:42|\n+------+-------------------+----------+------------------+------+---------+-------------------+\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute a ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run")," and confirm our model has been updated and matches the above results:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"clickhouse-user@clickhouse:~/imdb$  dbt run\n16:12:16  Running with dbt=1.1.0\n16:12:16  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n16:12:16\n16:12:17  Concurrency: 1 threads (target='dev')\n16:12:17\n16:12:17  1 of 1 START incremental model imdb_dbt.actor_summary........................... [RUN]\n16:12:24  1 of 1 OK created incremental model imdb_dbt.actor_summary...................... [OK in 6.82s]\n16:12:24\n16:12:24  Finished running 1 incremental model in 7.79s.\n16:12:24\n16:12:24  Completed successfully\n16:12:24\n16:12:24  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 2;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+-------------------+----------+------------------+------+---------+-------------------+\n|id    |name               |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+-------------------+----------+------------------+------+---------+-------------------+\n|845466|Clicky McClickHouse|910       |1.4687938697032283|21    |662      |2022-04-26 16:20:36|\n|45332 |Mel Blanc          |909       |5.7884792542982515|19    |148      |2022-04-26 16:17:42|\n+------+-------------------+----------+------------------+------+---------+-------------------+\n")))),(0,i.kt)("h3",{id:"internals"},"Internals"),(0,i.kt)("p",null,"We can identify the statements executed to achieve the above incremental update by querying ClickHouse\u2019s query log."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT event_time, query  FROM system.query_log WHERE type='QueryStart' AND query LIKE '%dbt%'\nAND event_time > subtractMinutes(now(), 15) ORDER BY event_time LIMIT 100;\n")),(0,i.kt)("p",null,"Adjust the above query to the period of execution. We leave result inspection to the user but highlight the general strategy used by the plugin to perform incremental updates:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"The plugin creates a temporary table ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_sumary__dbt_tmp"),". Rows that have changed are streamed into this table."),(0,i.kt)("li",{parentName:"ol"},"A new table, ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_summary_new,")," is created. The rows from the old table are, in turn, streamed from the old to new, with a check to make sure row ids do not exist in the temporary table. This effectively handles updates and duplicates."),(0,i.kt)("li",{parentName:"ol"},"The results from the temporary table are streamed into the new ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_summary")," table:"),(0,i.kt)("li",{parentName:"ol"},"Finally, the new table is exchanged atomically with the old version via an ",(0,i.kt)("inlineCode",{parentName:"li"},"EXCHANGE TABLES")," statement. The old and temporary tables are in turn dropped.")),(0,i.kt)("p",null,"This is visualized below:"),(0,i.kt)("img",{src:a(73385).Z,class:"image",alt:"incremental updates dbt",style:{width:"100%"}}),(0,i.kt)("p",null,"This strategy may encounter challenges on very large models. For further details see ",(0,i.kt)("a",{parentName:"p",href:"#limitations"},"Limitations"),"."),(0,i.kt)("h3",{id:"append-strategy-inserts-only-mode"},"Append Strategy (inserts-only mode)"),(0,i.kt)("p",null,"To overcome the limitations of large datasets in incremental models, the plugin uses the dbt configuration parameter ",(0,i.kt)("inlineCode",{parentName:"p"},"incremental_strategy"),". This can be set to the value ",(0,i.kt)("inlineCode",{parentName:"p"},"append"),". When set, updated rows are inserted directly into the target table (a.k.a ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb_dbt.actor_summary"),") and no temporary table is created.\nNote: Append only mode requires your data to be immutable or for duplicates to be acceptable. If you want an incremental table model that supports altered rows don\u2019t use this mode!"),(0,i.kt)("p",null,"To illustrate this mode, we will add another new actor and re-execute dbt run with ",(0,i.kt)("inlineCode",{parentName:"p"},"incremental_strategy='append'"),"."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Configure append only mode in actor_summary.sql:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='incremental', unique_key='id', incremental_strategy='append') }}\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Let\u2019s add another famous actor - Danny DeBito"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.actors VALUES (845467, 'Danny', 'DeBito', 'M');\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Let's star Danny in 920 random movies."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.roles\nSELECT now() as created_at, 845467 as actor_id, id as movie_id, 'Himself' as role\nFROM imdb.movies\nLIMIT 920 OFFSET 10000;\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute a dbt run and confirm that Danny was added to the actor-summary table"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"clickhouse-user@clickhouse:~/imdb$ dbt run\n16:12:16  Running with dbt=1.1.0\n16:12:16  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 186 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n16:12:16\n16:12:17  Concurrency: 1 threads (target='dev')\n16:12:17\n16:12:17  1 of 1 START incremental model imdb_dbt.actor_summary........................... [RUN]\n16:12:24  1 of 1 OK created incremental model imdb_dbt.actor_summary...................... [OK in 0.17s]\n16:12:24\n16:12:24  Finished running 1 incremental model in 0.19s.\n16:12:24\n16:12:24  Completed successfully\n16:12:24\n16:12:24  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 3;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+-------------------+----------+------------------+------+---------+-------------------+\n|id    |name               |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+-------------------+----------+------------------+------+---------+-------------------+\n|845467|Danny DeBito       |920       |1.4768987303293204|21    |670      |2022-04-26 16:22:06|\n|845466|Clicky McClickHouse|910       |1.4687938697032283|21    |662      |2022-04-26 16:20:36|\n|45332 |Mel Blanc          |909       |5.7884792542982515|19    |148      |2022-04-26 16:17:42|\n+------+-------------------+----------+------------------+------+---------+-------------------+\n")))),(0,i.kt)("p",null,"Note how much faster that incremental was compared to the insertion of Clicky."),(0,i.kt)("p",null,"Checking again the query_log table reveals the differences between the 2 incremental runs:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},'insert into imdb_dbt.actor_summary ("id", "name", "num_movies", "avg_rank", "genres", "directors", "updated_at")\nwith actor_summary as (\n   SELECT id,\n      any(actor_name) as name,\n      uniqExact(movie_id)    as num_movies,\n      avg(rank)                as avg_rank,\n      uniqExact(genre)         as genres,\n      uniqExact(director_name) as directors,\n      max(created_at) as updated_at\n   FROM (\n      SELECT imdb.actors.id as id,\n         concat(imdb.actors.first_name, \' \', imdb.actors.last_name) as actor_name,\n         imdb.movies.id as movie_id,\n         imdb.movies.rank as rank,\n         genre,\n         concat(imdb.directors.first_name, \' \', imdb.directors.last_name) as director_name,\n         created_at\n      FROM imdb.actors\n         JOIN imdb.roles ON imdb.roles.actor_id = imdb.actors.id\n         LEFT OUTER JOIN imdb.movies ON imdb.movies.id = imdb.roles.movie_id\n         LEFT OUTER JOIN imdb.genres ON imdb.genres.movie_id = imdb.movies.id\n         LEFT OUTER JOIN imdb.movie_directors ON imdb.movie_directors.movie_id = imdb.movies.id\n         LEFT OUTER JOIN imdb.directors ON imdb.directors.id = imdb.movie_directors.director_id\n   )\n   GROUP BY id\n)\n\nselect *\nfrom actor_summary\n-- this filter will only be applied on an incremental run\nwhere id > (select max(id) from imdb_dbt.actor_summary) or updated_at > (select max(updated_at) from imdb_dbt.actor_summary)\n')),(0,i.kt)("p",null,"In this run, only the new rows are added straight to imdb_dbt.actor_summary table and there is no table creation involved."),(0,i.kt)("h3",{id:"deleteinsert-mode-experimental"},"Delete+Insert mode (Experimental)"),(0,i.kt)("p",null,"Historically ClickHouse has had only limited support for updates and deletes, in the form of asynchronous ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/alter/"},"Mutations"),".  These can be extremely IO-intensive and should generally be avoided."),(0,i.kt)("p",null,"ClickHouse 22.8 introduced ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/delete"},"Lightweight deletes"),". These are currently experimental but offer a more performant means of deleting data."),(0,i.kt)("p",null,"This mode can be configured for a model via the ",(0,i.kt)("inlineCode",{parentName:"p"},"incremental_strategy")," parameter i.e."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='incremental', unique_key='id', incremental_strategy='delete+insert') }}\n")),(0,i.kt)("p",null,"This strategy operates directly on the target model's table, so if there is an issue during the operation, the data in the incremental model is likely to be in an invalid state -  there is no atomic update."),(0,i.kt)("p",null,"In summary, this approach:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"The plugin creates a temporary table ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_sumary__dbt_tmp"),". Rows that have changed are streamed into this table."),(0,i.kt)("li",{parentName:"ol"},"A ",(0,i.kt)("inlineCode",{parentName:"li"},"DELETE")," is issued against the current ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_summary")," table. Rows are deleted by id from ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_sumary__dbt_tmp")),(0,i.kt)("li",{parentName:"ol"},"The rows from ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_sumary__dbt_tmp")," are inserted into ",(0,i.kt)("inlineCode",{parentName:"li"},"actor_summary")," using an ",(0,i.kt)("inlineCode",{parentName:"li"},"INSERT INTO actor_summary SELECT * FROM actor_sumary__dbt_tmp"),".")),(0,i.kt)("p",null,"This process is shown below:"),(0,i.kt)("img",{src:a(63745).Z,class:"image",alt:"lightweight delete incremental",style:{width:"100%"}}),(0,i.kt)("h2",{id:"creating-a-snapshot"},"Creating a Snapshot"),(0,i.kt)("p",null,"dbt snapshots allow a record to be made of changes to a mutable model over time. This in turn allows point-in-time queries on models, where analysts can \u201clook back in time\u201d at the previous state of a model. This is achieved using ",(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row"},"type-2 Slowly Changing Dimensions")," where from and to date columns record when a row was valid. This functionality is supported by the ClickHouse plugin and is demonstrated below."),(0,i.kt)("p",null,"This example assumes you have completed ",(0,i.kt)("a",{parentName:"p",href:"#creating-an-incremental-materialization"},"Creating an Incremental Table Model"),". Make sure your actor_summary.sql doesn't set inserts_only=True. Your models/actor_summary.sql should look like this:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='incremental', unique_key='id') }}\n\nwith actor_summary as (\n    SELECT id,\n        any(actor_name) as name,\n        uniqExact(movie_id)    as num_movies,\n        avg(rank)                as avg_rank,\n        uniqExact(genre)         as genres,\n        uniqExact(director_name) as directors,\n        max(created_at) as updated_at\n    FROM (\n        SELECT {{ source('imdb', 'actors') }}.id as id,\n            concat({{ source('imdb', 'actors') }}.first_name, ' ', {{ source('imdb', 'actors') }}.last_name) as actor_name,\n            {{ source('imdb', 'movies') }}.id as movie_id,\n            {{ source('imdb', 'movies') }}.rank as rank,\n            genre,\n            concat({{ source('imdb', 'directors') }}.first_name, ' ', {{ source('imdb', 'directors') }}.last_name) as director_name,\n            created_at\n    FROM {{ source('imdb', 'actors') }}\n        JOIN {{ source('imdb', 'roles') }} ON {{ source('imdb', 'roles') }}.actor_id = {{ source('imdb', 'actors') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'movies') }} ON {{ source('imdb', 'movies') }}.id = {{ source('imdb', 'roles') }}.movie_id\n        LEFT OUTER JOIN {{ source('imdb', 'genres') }} ON {{ source('imdb', 'genres') }}.movie_id = {{ source('imdb', 'movies') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'movie_directors') }} ON {{ source('imdb', 'movie_directors') }}.movie_id = {{ source('imdb', 'movies') }}.id\n        LEFT OUTER JOIN {{ source('imdb', 'directors') }} ON {{ source('imdb', 'directors') }}.id = {{ source('imdb', 'movie_directors') }}.director_id\n    )\n    GROUP BY id\n)\nselect *\nfrom actor_summary\n\n{% if is_incremental() %}\n\n-- this filter will only be applied on an incremental run\nwhere id > (select max(id) from {{ this }}) or updated_at > (select max(updated_at) from {{this}})\n\n{% endif %}\n")),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Create a file ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary")," in the snapshots directory."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"}," touch snapshots/actor_summary.sql\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Update the contents of the actor_summary.sql file with the following content:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{% snapshot actor_summary_snapshot %}\n\n{{\nconfig(\ntarget_schema='snapshots',\nunique_key='id',\nstrategy='timestamp',\nupdated_at='updated_at',\n)\n}}\n\nselect * from {{ref('actor_summary')}}\n\n{% endsnapshot %}\n")))),(0,i.kt)("p",null,"A few observations regarding this content:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The select query defines the results you wish to snapshot over time. The function ref is used to reference our previously created actor_summary model."),(0,i.kt)("li",{parentName:"ul"},"We require a timestamp column to indicate record changes. Our updated_at column (see ",(0,i.kt)("a",{parentName:"li",href:"#creating-an-incremental-materialization"},"Creating an Incremental Table Model"),") can be used here. The parameter strategy indicates our use of a timestamp to denote updates, with the parameter updated_at specifying the column to use. If this is not present in your model you can alternatively use the ",(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/snapshots#check-strategy"},"check strategy"),". This is significantly more inefficient and requires the user to specify a list of columns to compare.  dbt compares the current and historical values of these columns, recording any changes (or doing nothing if identical).")),(0,i.kt)("ol",{start:3},(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Run the command ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt snapshot"),"."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"clickhouse-user@clickhouse:~/imdb$ dbt snapshot\n13:26:23  Running with dbt=1.1.0\n13:26:23  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics\n13:26:23\n13:26:25  Concurrency: 1 threads (target='dev')\n13:26:25\n13:26:25  1 of 1 START snapshot snapshots.actor_summary_snapshot...................... [RUN]\n13:26:25  1 of 1 OK snapshotted snapshots.actor_summary_snapshot...................... [OK in 0.79s]\n13:26:25\n13:26:25  Finished running 1 snapshot in 2.11s.\n13:26:25\n13:26:25  Completed successfully\n13:26:25\n13:26:25  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")))),(0,i.kt)("p",null,"Note how a table actor_summary_snapshot has been created in the snapshots db (determined by the target_schema parameter)."),(0,i.kt)("ol",{start:4},(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Sampling this data you will see how dbt has included the columns dbt_valid_from and dbt_valid_to. The latter has values set to null. Subsequent runs will update this."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT id, name, num_movies, dbt_valid_from, dbt_valid_to FROM snapshots.actor_summary_snapshot ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+----------+------------+----------+-------------------+------------+\n|id    |first_name|last_name   |num_movies|dbt_valid_from     |dbt_valid_to|\n+------+----------+------------+----------+-------------------+------------+\n|845467|Danny     |DeBito      |920       |2022-05-25 19:33:32|NULL        |\n|845466|Clicky    |McClickHouse|910       |2022-05-25 19:32:34|NULL        |\n|45332 |Mel       |Blanc       |909       |2022-05-25 19:31:47|NULL        |\n|621468|Bess      |Flowers     |672       |2022-05-25 19:31:47|NULL        |\n|283127|Tom       |London      |549       |2022-05-25 19:31:47|NULL        |\n+------+----------+------------+----------+-------------------+------------+\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Make our favorite actor Clicky McClickHouse appear in another 10 films."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.roles\nSELECT now() as created_at, 845466 as actor_id, rand(number) % 412320 as movie_id, 'Himself' as role\nFROM system.numbers\nLIMIT 10;\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Re-run the dbt run command from the imdb directory. This will update the incremental model. Once this is complete, run the dbt snapshot to capture the changes."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"clickhouse-user@clickhouse:~/imdb$ dbt run\n13:46:14  Running with dbt=1.1.0\n13:46:14  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics\n13:46:14\n13:46:15  Concurrency: 1 threads (target='dev')\n13:46:15\n13:46:15  1 of 1 START incremental model imdb_dbt.actor_summary....................... [RUN]\n13:46:18  1 of 1 OK created incremental model imdb_dbt.actor_summary.................. [OK in 2.76s]\n13:46:18\n13:46:18  Finished running 1 incremental model in 3.73s.\n13:46:18\n13:46:18  Completed successfully\n13:46:18\n13:46:18  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n\nclickhouse-user@clickhouse:~/imdb$ dbt snapshot\n13:46:26  Running with dbt=1.1.0\n13:46:26  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics\n13:46:26\n13:46:27  Concurrency: 1 threads (target='dev')\n13:46:27\n13:46:27  1 of 1 START snapshot snapshots.actor_summary_snapshot...................... [RUN]\n13:46:31  1 of 1 OK snapshotted snapshots.actor_summary_snapshot...................... [OK in 4.05s]\n13:46:31\n13:46:31  Finished running 1 snapshot in 5.02s.\n13:46:31\n13:46:31  Completed successfully\n13:46:31\n13:46:31  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"If we now query our snapshot, notice we have 2 rows for Clicky McClickHouse. Our previous entry now has a dbt_valid_to value. Our new value is recorded with the same value in the dbt_valid_from column, and a dbt_valid_to value of null. If we did have new rows, these would also be appended to the snapshot."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT id, name, num_movies, dbt_valid_from, dbt_valid_to FROM snapshots.actor_summary_snapshot ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+----------+------------+----------+-------------------+-------------------+\n|id    |first_name|last_name   |num_movies|dbt_valid_from     |dbt_valid_to       |\n+------+----------+------------+----------+-------------------+-------------------+\n|845467|Danny     |DeBito      |920       |2022-05-25 19:33:32|NULL               |\n|845466|Clicky    |McClickHouse|920       |2022-05-25 19:34:37|NULL               |\n|845466|Clicky    |McClickHouse|910       |2022-05-25 19:32:34|2022-05-25 19:34:37|\n|45332 |Mel       |Blanc       |909       |2022-05-25 19:31:47|NULL               |\n|621468|Bess      |Flowers     |672       |2022-05-25 19:31:47|NULL               |\n+------+----------+------------+----------+-------------------+-------------------+\n")))),(0,i.kt)("p",null,"For further details on dbt snapshots see ",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/building-a-dbt-project/snapshots"},"here"),"."),(0,i.kt)("h2",{id:"using-seeds"},"Using Seeds"),(0,i.kt)("p",null,"dbt provides the ability to load data from CSV files. This capability is not suited to loading large exports of a database and is more designed for small files typically used for code tables and ",(0,i.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/dictionaries"},"dictionaries"),", e.g. mapping country codes to country names. For a simple example, we generate and then upload a list of genre codes using the seed functionality."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"We generate a list of genre codes from our existing dataset. From the dbt directory, use the ",(0,i.kt)("inlineCode",{parentName:"p"},"clickhouse-client")," to create a file ",(0,i.kt)("inlineCode",{parentName:"p"},"seeds/genre_codes.csv"),":"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'clickhouse-user@clickhouse:~/imdb$ clickhouse-client --password <password> --query\n"SELECT genre, ucase(substring(genre, 1, 3)) as code FROM imdb.genres GROUP BY genre\nLIMIT 100 FORMAT CSVWithNames" > seeds/genre_codes.csv\n'))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute the ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt seed")," command. This will create a new table ",(0,i.kt)("inlineCode",{parentName:"p"},"genre_codes")," in our database ",(0,i.kt)("inlineCode",{parentName:"p"},"imdb_dbt")," (as defined by our schema configuration) with the rows from our csv file."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$ dbt seed\n17:03:23  Running with dbt=1.1.0\n17:03:23  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 1 seed file, 6 sources, 0 exposures, 0 metrics\n17:03:23\n17:03:24  Concurrency: 1 threads (target='dev')\n17:03:24\n17:03:24  1 of 1 START seed file imdb_dbt.genre_codes..................................... [RUN]\n17:03:24  1 of 1 OK loaded seed file imdb_dbt.genre_codes................................. [INSERT 21 in 0.65s]\n17:03:24\n17:03:24  Finished running 1 seed in 1.62s.\n17:03:24\n17:03:24  Completed successfully\n17:03:24\n17:03:24  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Confirm these have been loaded:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.genre_codes LIMIT 10;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+-------+----+\n|genre  |code|\n+-------+----+\n|Drama  |DRA |\n|Romance|ROM |\n|Short  |SHO |\n|Mystery|MYS |\n|Adult  |ADU |\n|Family |FAM |\n\n|Action |ACT |\n|Sci-Fi |SCI |\n|Horror |HOR |\n|War    |WAR |\n+-------+----+=\n")))),(0,i.kt)("h2",{id:"limitations"},"Limitations"),(0,i.kt)("p",null,"The current ClickHouse plugin for dbt has several limitations users should be aware of:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"The plugin currently materializes models as tables using an ",(0,i.kt)("inlineCode",{parentName:"li"},"INSERT TO SELECT"),". This effectively means data duplication. Very large datasets (PB) can result in extremely long run times, making some models unviable. Aim to minimize the number of rows returned by any query, utilizing GROUP BY where possible. Prefer models which summarize data over those which simply perform a transform whilst maintaining row counts of the source."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations#ephemeral"},"Ephemeral materializations")," are not supported."),(0,i.kt)("li",{parentName:"ol"},"To use Distributed tables to represent a model, users must create the underlying replicated tables on each node manually. The Distributed table can, in turn, be created on top of these. The plugin does not manage cluster creation."),(0,i.kt)("li",{parentName:"ol"},"Only the ClickHouse native protocol is supported. There is no support for HTTP."),(0,i.kt)("li",{parentName:"ol"},"When dbt creates a relation (table/view) in a database, it usually creates it as: ",(0,i.kt)("inlineCode",{parentName:"li"},"{{ database }}.{{ schema }}.{{ table/view id }}"),". ClickHouse has no notion of schemas. The plugin therefore uses ",(0,i.kt)("inlineCode",{parentName:"li"},"{{schema}}.{{ table/view id }}"),", where ",(0,i.kt)("inlineCode",{parentName:"li"},"schema")," is the ClickHouse database.")),(0,i.kt)("p",null,"Further Information"),(0,i.kt)("p",null,"The previous guides only touch the surface of dbt functionality. Users are recommended to read the excellent ",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/introduction"},"dbt documentation"),"."),(0,i.kt)("p",null,"Additional configuration for the plugin is described ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/silentsokolov/dbt-clickhouse#model-configuration"},"here"),"."))}p.isMDXComponent=!0},97988:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_01-24a161b0216de65d39a8785fb345730e.png"},60897:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_02-8318d15ea0eafec005a86dbacfbe4d58.png"},44604:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_03-b9c1ccc74eae7f23956f59dc8c9c79ab.png"},39232:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_04-e9de140479a78612317ccd005190c381.png"},73385:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_05-1e364a9c0b3e8d517a559b582c66571c.png"},63745:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/dbt_06-179ed8803cfcbb5ed7661a25cf33cb30.png"}}]);
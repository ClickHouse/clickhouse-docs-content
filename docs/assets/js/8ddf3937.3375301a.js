"use strict";(self.webpackChunknew_nav_docusaurus_2_2=self.webpackChunknew_nav_docusaurus_2_2||[]).push([[21166],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var n=a(67294);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){s(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,s=function(e,t){if(null==e)return{};var a,n,s={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(s[a]=e[a]);return s}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(s[a]=e[a])}return s}var o=n.createContext({}),p=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(o.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,s=e.mdxType,r=e.originalType,o=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),d=p(a),c=s,h=d["".concat(o,".").concat(c)]||d[c]||u[c]||r;return a?n.createElement(h,i(i({ref:t},m),{},{components:a})):n.createElement(h,i({ref:t},m))}));function h(e,t){var a=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var r=a.length,i=new Array(r);i[0]=c;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[d]="string"==typeof e?e:s,i[1]=l;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},71844:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var n=a(87462),s=(a(67294),a(3905));const r={slug:"/en/integrations/data-formats/json",sidebar_label:"JSON",sidebar_position:2,description:"Working with JSON in ClickHouse"},i="Working with JSON in ClickHouse",l={unversionedId:"en/integrations/data-ingestion/data-formats/json",id:"en/integrations/data-ingestion/data-formats/json",title:"Working with JSON in ClickHouse",description:"Working with JSON in ClickHouse",source:"@site/docs/en/integrations/data-ingestion/data-formats/json.md",sourceDirName:"en/integrations/data-ingestion/data-formats",slug:"/en/integrations/data-formats/json",permalink:"/docs/en/integrations/data-formats/json",draft:!1,editUrl:"https://github.com/ClickHouse/clickhouse-docs/blob/main/docs/en/integrations/data-ingestion/data-formats/json.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{slug:"/en/integrations/data-formats/json",sidebar_label:"JSON",sidebar_position:2,description:"Working with JSON in ClickHouse"},sidebar:"docs",previous:{title:"CSV and TSV",permalink:"/docs/en/integrations/data-formats/csv-tsv"},next:{title:"Parquet",permalink:"/docs/en/integrations/data-formats/parquet"}},o={},p=[{value:"Loading JSON in 5 steps",id:"loading-json-in-5-steps",level:2},{value:"Examine the structure of the JSON file",id:"examine-the-structure-of-the-json-file",level:3},{value:"DESCRIBE",id:"describe",level:5},{value:"SELECT",id:"select",level:5},{value:"Create a ClickHouse table",id:"create-a-clickhouse-table",level:3},{value:"Describe the table and note the <code>request</code> column",id:"describe-the-table-and-note-the-request-column",level:4},{value:"Insert one row",id:"insert-one-row",level:3},{value:"Verify",id:"verify",level:3},{value:"Insert the dataset",id:"insert-the-dataset",level:3},{value:"Query the data",id:"query-the-data",level:3},{value:"More information",id:"more-information",level:3},{value:"Limitations and other approaches",id:"limitations-and-other-approaches",level:4},{value:"JSON input and output formats",id:"json-input-and-output-formats",level:4},{value:"Structured Approach",id:"structured-approach",level:2},{value:"Semi-Structured Approach",id:"semi-structured-approach",level:2},{value:"Overview",id:"overview",level:3},{value:"Relying on Schema Inference",id:"relying-on-schema-inference",level:3},{value:"JSON Object Type",id:"json-object-type",level:3},{value:"Selecting Dynamic Subcolumns",id:"selecting-dynamic-subcolumns",level:3},{value:"Adding Primary Keys",id:"adding-primary-keys",level:3},{value:"Limitations and Best Practices",id:"limitations-and-best-practices",level:3},{value:"Handling Data Changes",id:"handling-data-changes",level:3},{value:"Adding Columns",id:"adding-columns",level:4},{value:"Changing Columns",id:"changing-columns",level:4},{value:"Handling JSON Formats",id:"handling-json-formats",level:3},{value:"Importing and exporting JSON data in ClickHouse",id:"importing-and-exporting-json-data-in-clickhouse",level:2},{value:"Importing JSON data",id:"importing-json-data",level:3},{value:"Importing from an array of JSON objects",id:"importing-from-an-array-of-json-objects",level:4},{value:"Handling NDJSON (line delimited JSON)",id:"handling-ndjson-line-delimited-json",level:5},{value:"Importing from JSON object keys",id:"importing-from-json-object-keys",level:4},{value:"Importing parent object key values",id:"importing-parent-object-key-values",level:5},{value:"Importing from JSON arrays",id:"importing-from-json-arrays",level:4},{value:"Importing individual columns from JSON arrays",id:"importing-individual-columns-from-json-arrays",level:4},{value:"Saving JSON objects instead of parsing",id:"saving-json-objects-instead-of-parsing",level:4},{value:"Data types detection when importing JSON data",id:"data-types-detection-when-importing-json-data",level:3},{value:"JSON objects with nested objects",id:"json-objects-with-nested-objects",level:3},{value:"Nested JSON objects",id:"nested-json-objects",level:4},{value:"Skipping unknown columns",id:"skipping-unknown-columns",level:3},{value:"Exporting JSON data",id:"exporting-json-data",level:3},{value:"Overriding data types as strings",id:"overriding-data-types-as-strings",level:4},{value:"Exporting metadata together with data",id:"exporting-metadata-together-with-data",level:4},{value:"Compact way to export JSON data and structure",id:"compact-way-to-export-json-data-and-structure",level:5},{value:"Exporting JSON to a file",id:"exporting-json-to-a-file",level:4},{value:"Importing and exporting BSON",id:"importing-and-exporting-bson",level:3},{value:"Other formats",id:"other-formats",level:3},{value:"Other Approaches",id:"other-approaches",level:2},{value:"Handle as Structured Data",id:"handle-as-structured-data",level:3},{value:"Using Nested",id:"using-nested",level:4},{value:"Using Tuples",id:"using-tuples",level:4},{value:"Using Maps",id:"using-maps",level:4},{value:"Nested vs Tuple vs Map",id:"nested-vs-tuple-vs-map",level:4},{value:"Store as String",id:"store-as-string",level:3},{value:"Visit Functions",id:"visit-functions",level:4},{value:"Using Pairwise Arrays",id:"using-pairwise-arrays",level:3},{value:"Hybrid Approach with Materialized Columns",id:"hybrid-approach-with-materialized-columns",level:3},{value:"Default vs Materialized",id:"default-vs-materialized",level:4},{value:"Assessing Storage Usage",id:"assessing-storage-usage",level:4},{value:"Using Materialized Views",id:"using-materialized-views",level:4},{value:"Updating Materialized Views",id:"updating-materialized-views",level:4},{value:"Using for Pairwise Arrays",id:"using-for-pairwise-arrays",level:4},{value:"Related Content",id:"related-content",level:2}],m={toc:p},d="wrapper";function u(e){let{components:t,...r}=e;return(0,s.kt)(d,(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"working-with-json-in-clickhouse"},"Working with JSON in ClickHouse"),(0,s.kt)("p",null,"ClickHouse provides several approaches for handling JSON, each with its respective pros and cons and usage. More recent versions of ClickHouse have introduced new types which allow even greater flexibility and performance for JSON storage and querying."),(0,s.kt)("p",null,"For example purposes, we utilize two datasets: a 1m row subset of the ",(0,s.kt)("a",{parentName:"p",href:"https://ghe.clickhouse.tech/#how-this-dataset-is-created"},"Github dataset")," and an example ",(0,s.kt)("a",{parentName:"p",href:"https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz"},"NGINX log")," in JSON format. The former includes nested columns, useful for example purposes. It is also deliberately sparse, which helps illustrate some challenges of JSON. The latter allows us to discuss standard techniques for JSON logs."),(0,s.kt)("h2",{id:"loading-json-in-5-steps"},"Loading JSON in 5 steps"),(0,s.kt)("p",null,"This guide walks through the process to load logging data that is\nin a JSON formatted file in S3.  In order to do this:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Examine the file format by selecting one row using the S3 function"),(0,s.kt)("li",{parentName:"ul"},"Create a table to store the data in ClickHouse"),(0,s.kt)("li",{parentName:"ul"},"Load a single row of nested JSON"),(0,s.kt)("li",{parentName:"ul"},"Verify the correct storage of the nested JSON"),(0,s.kt)("li",{parentName:"ul"},"Import the dataset from S3")),(0,s.kt)("admonition",{type:"note"},(0,s.kt)("p",{parentName:"admonition"},"This tutorial requires ClickHouse version 22.11 or higher.")),(0,s.kt)("h3",{id:"examine-the-structure-of-the-json-file"},"Examine the structure of the JSON file"),(0,s.kt)("p",null,"Examine the structure and one record from the log file in S3.  The ",(0,s.kt)("inlineCode",{parentName:"p"},"s3")," function\nretrieves and decompresses the file and allows querying the file\nin S3 without loading it."),(0,s.kt)("p",null,"This is what a row of the file contains:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{"@timestamp":893964617,"clientip":"40.135.0.0","request":{"method":"GET","path":"/images/hm_bg.jpg","version":"HTTP/1.0"},"status":200,"size":24736}\n')),(0,s.kt)("p",null,"It is also very useful to look at the description of the file returned by the DESCRIBE command and a SELECT."),(0,s.kt)("h5",{id:"describe"},"DESCRIBE"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow');\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u252c\u2500comment\u2500\u252c\u2500codec_expression\u2500\u252c\u2500ttl_expression\u2500\u2510\n\u2502 @timestamp \u2502 Nullable(Int64)               \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 clientip   \u2502 Nullable(String)              \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 request    \u2502 Map(String, Nullable(String)) \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 status     \u2502 Nullable(Int64)               \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 size       \u2502 Nullable(Int64)               \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h5",{id:"select"},"SELECT"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow') LIMIT 1;\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500@timestamp\u2500\u252c\u2500clientip\u2500\u2500\u2500\u252c\u2500request\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500status\u2500\u252c\u2500\u2500size\u2500\u2510\n\u2502  893964617 \u2502 40.135.0.0 \u2502 {'method':'GET','path':'/images/hm_bg.jpg','version':'HTTP/1.0'} \u2502    200 \u2502 24736 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"Note that the ",(0,s.kt)("inlineCode",{parentName:"p"},"response")," field contains nested JSON, it is more\nefficient for the users of the log data if that JSON is also extracted\ninto separate fields. The next two steps will be performed with this\noptimization in mind."),(0,s.kt)("h3",{id:"create-a-clickhouse-table"},"Create a ClickHouse table"),(0,s.kt)("p",null,"To maximize the usefulness of the data we\nneed to extract the nested ",(0,s.kt)("inlineCode",{parentName:"p"},"method"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"path"),", and ",(0,s.kt)("inlineCode",{parentName:"p"},"version")," fields under ",(0,s.kt)("inlineCode",{parentName:"p"},"request"),".  To prepare for this, create a table including those nested fields:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE http\n(\n    `@timestamp` DateTime,\n    `clientip` IPv4,\n# highlight-next-line\n    `request` Tuple(method LowCardinality(String), path String, version LowCardinality(String)),\n    `status` UInt16,\n    `size` UInt32\n)\nENGINE = MergeTree\nORDER BY (status, `@timestamp`)\n")),(0,s.kt)("h4",{id:"describe-the-table-and-note-the-request-column"},"Describe the table and note the ",(0,s.kt)("inlineCode",{parentName:"h4"},"request")," column"),(0,s.kt)("p",null,"The ",(0,s.kt)("inlineCode",{parentName:"p"},"request")," field from the JSON file will be stored as a tuple."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE TABLE http\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500name\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u252c\u2500comment\u2500\u252c\u2500codec_expression\u2500\u252c\u2500ttl_expression\u2500\u2510\n\u2502 @timestamp \u2502 DateTime                                                                          \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 clientip   \u2502 IPv4                                                                              \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n# highlight-next-line\n\u2502 request    \u2502 Tuple(method LowCardinality(String), path String, version LowCardinality(String)) \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 status     \u2502 UInt16                                                                            \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 size       \u2502 UInt32                                                                            \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h3",{id:"insert-one-row"},"Insert one row"),(0,s.kt)("p",null,"When the response is inserted, all three components of the request are inserted."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http SELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz', 'JSONEachRow')\nLIMIT 1\n")),(0,s.kt)("h3",{id:"verify"},"Verify"),(0,s.kt)("p",null,"The ",(0,s.kt)("inlineCode",{parentName:"p"},"method"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"path"),", and ",(0,s.kt)("inlineCode",{parentName:"p"},"version")," should be available to query individually."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    request.method,\n    request.path,\n    request.version\nFROM http\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500request.method\u2500\u252c\u2500request.path\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500request.version\u2500\u2510\n\u2502 GET            \u2502 /images/hm_bg.jpg \u2502 HTTP/1.0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h3",{id:"insert-the-dataset"},"Insert the dataset"),(0,s.kt)("admonition",{type:"tip"},(0,s.kt)("p",{parentName:"admonition"},"The full dataset is 10 million rows, you can use ",(0,s.kt)("inlineCode",{parentName:"p"},"LIMIT")," to reduce\nthe number of rows inserted.  The query shown inserts 1 million rows.")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http SELECT *\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz', 'JSONEachRow')\nLIMIT 1000000;\n")),(0,s.kt)("h3",{id:"query-the-data"},"Query the data"),(0,s.kt)("p",null,"This query gives a count of the queries between January 1st and June 1st grouped by the method and status."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    status,\n# highlight-next-line\n    request.method AS method,\n    count() AS c\nFROM http\nWHERE (status >= 400) AND ((`@timestamp` >= '1998-01-01 00:00:00') AND (`@timestamp` <= '1998-06-01 00:00:00'))\nGROUP BY\n    method,\n    status\nORDER BY c DESC\nLIMIT 5\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500status\u2500\u252c\u2500method\u2500\u2500\u252c\u2500\u2500\u2500\u2500c\u2500\u2510\n\u2502    404 \u2502 GET     \u2502 1161 \u2502\n\u2502    500 \u2502 POST    \u2502   14 \u2502\n\u2502    400 \u2502 GET     \u2502   13 \u2502\n\u2502    404 \u2502 OPTIONS \u2502   12 \u2502\n\u2502    500 \u2502 GET     \u2502    6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h3",{id:"more-information"},"More information"),(0,s.kt)("h4",{id:"limitations-and-other-approaches"},"Limitations and other approaches"),(0,s.kt)("p",null,"If any of the fields in the tuple (",(0,s.kt)("inlineCode",{parentName:"p"},"request."),": ",(0,s.kt)("inlineCode",{parentName:"p"},"method"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"path"),", and ",(0,s.kt)("inlineCode",{parentName:"p"},"version"),") need to be included in the ORDER BY or PRIMARY KEY of the table, then the entire tuple must be added to the ORDER BY or PRIMARY Key.  For more information on the pros and cons of this method and other methods of loading JSON see ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches"},"JSON other approaches"),"."),(0,s.kt)("h4",{id:"json-input-and-output-formats"},"JSON input and output formats"),(0,s.kt)("p",null,"  The format ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONEachRow")," is used in this guide, but there are other options, see the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#json"},"input and output format docs"),"."),(0,s.kt)("h2",{id:"structured-approach"},"Structured Approach"),(0,s.kt)("p",null,"First, we confirm we can read the JSON dataset and highlight the challenges of handling semi-structured data using more traditional types used in other databases. We don\u2019t rely on Schema inference to map the JSON fields to columns in the example below - instead, we specify a format of JSONEachRow and map the fields explicitly to columns in the s3 functions."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT type, `actor.display_login`, `repo.name`, created_at\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022-flat.ndjson.gz',\n        'JSONEachRow',\n        'type String, `actor.avatar_url` String, `actor.display_login` String, ' ||\n        '`actor.id` Float64, `actor.login` String, `actor.url` String, `repo.id` Float64, ' ||\n        '`repo.name` String, `repo.url` String, created_at String, `payload.pull_request.updated_at` String, ' ||\n        '`payload.action` String, `payload.ref` String, `payload.ref_type` String, ' ||\n        '`payload.pull_request.user.login` String, `payload.pull_request.number` Float64, ' ||\n        '`payload.pull_request.title` String, `payload.pull_request.state` String, ' ||\n        '`payload.pull_request.author_association` String, `payload.pull_request.head.ref` String, ' ||\n        '`payload.pull_request.head.sha` String, `payload.pull_request.base.ref` String, ' ||\n        '`payload.pull_request.base.sha` String, `payload.size` Float64, `payload.distinct_size` Float64')\nLIMIT 10;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"type"),(0,s.kt)("th",{parentName:"tr",align:"left"},"actor.display","_","login"),(0,s.kt)("th",{parentName:"tr",align:"left"},"repo.name"),(0,s.kt)("th",{parentName:"tr",align:"left"},"created","_","at"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Lakshmipatil2021"),(0,s.kt)("td",{parentName:"tr",align:"left"},"revacprogramming/pps-test1-Lakshmipatil2021"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"MemberEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"KStevenT"),(0,s.kt)("td",{parentName:"tr",align:"left"},"KStevenT/HTML","_","ExternalWorkshop"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Soumojit28"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Soumojit28/Oxytocin"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"github-actions"),(0,s.kt)("td",{parentName:"tr",align:"left"},"diogoaraujo017/diogoaraujo017"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Aman-Sonwani"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Aman-Sonwani/crwn-clothing"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"huangshanyoumumingwutong"),(0,s.kt)("td",{parentName:"tr",align:"left"},"huangshanyoumumingwutong/picgo"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PullRequestEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"rfprod"),(0,s.kt)("td",{parentName:"tr",align:"left"},"rfprod/nx-ng-starter"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Helikopter-Bojowy"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Helikopter-Bojowy/Exp-na-helikopterze"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"IssueCommentEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"PRMerger-test-1"),(0,s.kt)("td",{parentName:"tr",align:"left"},"MicrosoftDocs/CSIDev-Public"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"github-actions"),(0,s.kt)("td",{parentName:"tr",align:"left"},"pioug/yield-data"),(0,s.kt)("td",{parentName:"tr",align:"left"},"2022-01-04T07:00:00Z")))),(0,s.kt)("p",null,"Note this dataset is a subset of the example used later, with no nested objects within the JSON itself - the fields have been flattened using a period separator. Although nested objects can be handled through an explicit mapping, it requires either the use of the new JSON object field or (for older ClickHouse versions) Tuples, Map and Nested structures (see ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches"},"Other Approaches"),") further complicate usage."),(0,s.kt)("p",null,"This approach requires mapping all fields and has obvious limitations when the JSON is potentially dynamic or unknown. We could use an INSERT INTO SELECT statement to persist the results into a local Merge Tree table. Defining such a table would require the user to know all fields and express the verbose definition below."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE table github_flat\n(\n   type                                      String,\n   `actor.avatar_url`                        String,\n   `actor.display_login`                     String,\n   `actor.id`                                Float64,\n   `actor.login`                             String,\n   `actor.url`                               String,\n   `repo.id`                                 Float64,\n   `repo.name`                               String,\n   `repo.url`                                String,\n   created_at                                String,\n   `payload.pull_request.updated_at`         String,\n   `payload.action`                          String,\n   `payload.ref`                             String,\n   `payload.ref_type`                        String,\n   `payload.pull_request.user.login`         String,\n   `payload.pull_request.number`             Float64,\n   `payload.pull_request.title`              String,\n   `payload.pull_request.state`              String,\n   `payload.pull_request.author_association` String,\n   `payload.pull_request.head.ref`           String,\n   `payload.pull_request.head.sha`           String,\n   `payload.pull_request.base.ref`           String,\n   `payload.pull_request.base.sha`           String,\n   `payload.size`                            Float64,\n   `payload.distinct_size`                   Float64\n) ENGINE = MergeTree ORDER BY (type, `repo.name`, created_at);\n\nINSERT INTO github_flat SELECT * FROM s3 ('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022-flat.ndjson.gz', 'JSONEachRow');\n\nSELECT count() from github_flat;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"count","(",")"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"1000000")))),(0,s.kt)("p",null,"Furthermore, if new properties are added to the JSON, the table would need to be updated, i.e., via ALTER TABLE. Naturally, this leads us to use ClickHouse\u2019s semi-structured features."),(0,s.kt)("h2",{id:"semi-structured-approach"},"Semi-Structured Approach"),(0,s.kt)("h3",{id:"overview"},"Overview"),(0,s.kt)("p",null,"To address the challenges of semi-structured data ClickHouse provides a JSON Object type. This feature is only available in versions later than 22.3.1. It represents the future preferred mechanism for handling arbitrary JSON. The alternative approaches described ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches"},"later"),", which partially rely on imposing a strict schema, still have validity as extracting JSON fields into dedicated columns allows these to be optimized with codecs or utilized primary/sort keys."),(0,s.kt)("p",null,"The JSON Object type is advantageous when dealing with complex nested structures, which are subject to change. The type automatically infers the columns from the structure during insertion and merges these into the existing table schema. By storing JSON keys and their values as columns and dynamic subcolumns, ClickHouse can exploit the same optimizations used for structured data and thus provide comparable performance. The user is also provided with an intuitive path syntax for column selection. Furthermore, a table can contain a JSON object column with a flexible schema and more strict conventional columns with predefined types."),(0,s.kt)("p",null,"It is important to note that the JSON type primarily syntactically enhances JSON handling at insertion and query time, i.e., it still exploits the native existing ClickHouse types for the columns, with JSON objects represented using the ",(0,s.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/sql-reference/data-types/tuple/"},"Tuple type"),". As a result, previously, manual schema handling is handled automatically with querying significantly simpler."),(0,s.kt)("h3",{id:"relying-on-schema-inference"},"Relying on Schema Inference"),(0,s.kt)("p",null,"Note that recent versions of ClickHouse (22.4.1+) will infer the schema for JSONEachRow. This inference will also work for JSON objects with nested structures. These will be inferred as JSON object fields. For example, executing a DESCRIBE shows the detected schema for the file, including the actor fields:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022.ndjson.gz',\n'JSONEachRow') SETTINGS input_format_max_rows_to_read_for_schema_inference=100;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"name"),(0,s.kt)("th",{parentName:"tr",align:"left"},"type"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"type"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Nullable","(","String",")")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"actor"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Object","(","'json'",")")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"repo"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Object","(","'json'",")")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"created","_","at"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Nullable","(","String",")")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"payload"),(0,s.kt)("td",{parentName:"tr",align:"left"},"Object","(","'json'",")")))),(0,s.kt)("p",null,"Note the setting ",(0,s.kt)("inlineCode",{parentName:"p"},"input_format_max_rows_to_read_for_schema_inference"),". This determines the number of rows used to infer a schema. In this case, the schema can be inferred within the default of 100 rows. If the first 100 rows contained columns with null values, this would need to be set higher. This schema inference simplifies SELECT statements. Try executing the following to see how the actor and repo columns are returned as JSON."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT type, actor, repo FROM\ns3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022.ndjson.gz',\n'JSONEachRow') LIMIT 2;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"type"),(0,s.kt)("th",{parentName:"tr",align:"left"},"actor"),(0,s.kt)("th",{parentName:"tr",align:"left"},"repo"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},'{"avatar',"_",'url":"https:',"\\","/","\\","/avatars.githubusercontent.com","\\","/u","\\",'/93110249?","display',"_",'login":"Lakshmipatil2021","id":93110249,"login":"Lakshmipatil2021","url":"https:',"\\","/","\\","/api.github.com","\\","/users","\\",'/Lakshmipatil2021"}'),(0,s.kt)("td",{parentName:"tr",align:"left"},'{"id":429298592,"name":"revacprogramming',"\\",'/pps-test1-Lakshmipatil2021","url":"https:',"\\","/","\\","/api.github.com","\\","/repos","\\","/revacprogramming","\\",'/pps-test1-Lakshmipatil2021"}')),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"MemberEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},'{"avatar',"_",'url":"https:',"\\","/","\\","/avatars.githubusercontent.com","\\","/u","\\",'/95751520?","display',"_",'login":"KStevenT","id":95751520,"login":"KStevenT","url":"https:',"\\","/","\\","/api.github.com","\\","/users","\\",'/KStevenT"}'),(0,s.kt)("td",{parentName:"tr",align:"left"},'{"id":443103546,"name":"KStevenT',"\\","/HTML","_",'ExternalWorkshop","url":"https:',"\\","/","\\","/api.github.com","\\","/repos","\\","/KStevenT","\\","/HTML","_",'ExternalWorkshop"}')))),(0,s.kt)("p",null,"Schema inference and the introduction of the JSON Object Type allow us to handle nested data elegantly and avoid verbose definitions. However, we need to treat the entire row as a JSON object for dynamic properties on the root.  Version 22.4 of ClickHouse introduces the JSONAsObject format to assist with this."),(0,s.kt)("h3",{id:"json-object-type"},"JSON Object Type"),(0,s.kt)("p",null,"Using the same dataset as above, we explicitly declare that each row is a single object via the ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONAsObject")," format.  This single object is mapped to a field event of the type ",(0,s.kt)("inlineCode",{parentName:"p"},"Object(JSON)")," - in this case, we use the shorthand ",(0,s.kt)("inlineCode",{parentName:"p"},"JSON.")," Note if we don\u2019t explicitly specify ",(0,s.kt)("inlineCode",{parentName:"p"},"event")," as the field name in the s3 function, a field ",(0,s.kt)("inlineCode",{parentName:"p"},"json")," will be used:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022.ndjson.gz',\n'JSONAsObject', 'event JSON') LIMIT 1;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"event"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},'{"type":"PushEvent","actor.avatar',"_",'url":"https:',"\\","/","\\","/avatars.githubusercontent.com","\\","/u","\\",'/93110249?","actor.display',"_",'login":"Lakshmipatil2021","actor.id":93110249,"actor.login":"Lakshmipatil2021","actor.url":"https:',"\\","/","\\","/api.github.com","\\","/users","\\",'/Lakshmipatil2021","repo.id":429298592,"repo.name":"revacprogramming',"\\",'/pps-test1-Lakshmipatil2021","repo.url":"https:',"\\","/","\\","/api.github.com","\\","/repos","\\","/revacprogramming","\\",'/pps-test1-Lakshmipatil2021","created',"_",'at":"2022-01-04T07:00:00Z","payload.pull',"_","request.updated","_",'at":"","payload.pull',"_",'request.user.login":"","payload.pull',"_",'request.number":0,"payload.pull',"_",'request.title":"","payload.pull',"_",'request.state":"","payload.pull',"_","request.author","_",'association":"","payload.pull',"_",'request.head.ref":"","payload.pull',"_",'request.head.sha":"","payload.pull',"_",'request.base.ref":"","payload.pull',"_",'request.base.sha":"","payload.action":"","payload.ref":"refs',"\\","/heads","\\",'/main","payload.ref',"_",'type":"","payload.size":1,"payload.distinct',"_",'size":1}')))),(0,s.kt)("p",null,"To query this data effectively, we currently need to store it into a MergeTree. This is subject to change in later versions. We, therefore, create a table and insert the rows using an INSERT INTO SELECT."),(0,s.kt)("p",null,"First, create the table before inserting the rows. This can take a few minutes depending on the hardware and network latency to the s3 source bucket:"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Note the use of allow_experimental_object_type as the JSON object type is still an experimental feature.")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS github_json;\n\nSET allow_experimental_object_type=1;\n\nCREATE table github_json(event JSON) ENGINE = MergeTree ORDER BY tuple()\n\nINSERT INTO github_json SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/github/github-2022.ndjson.gz',\nJSONAsObject, 'event JSON');\n")),(0,s.kt)("p",null,"Confirm the table schema and row count as 1m."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT count() FROM github_json;\n\nDESCRIBE github_json;\n\nObject('json')\n")),(0,s.kt)("p",null,"While the above confirms each row is treated as a JSON object, it provides no information on how the fields in the JSON are mapped columns. To obtain this, we can utilize the setting ",(0,s.kt)("inlineCode",{parentName:"p"},"describe_extend_object_types"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE github_json SETTINGS describe_extend_object_types=1;\n\nTuple(actor Tuple(avatar_url String, display_login String, id Int32, login String, url String),\ncreated_at String, payload Tuple(action String, distinct_size Int32,\npull_request Tuple(author_association String, base Tuple(ref String, sha String),\nhead Tuple(ref String, sha String), number Int32, state String, title String,\nupdated_at String, user Tuple(login String)), ref String, ref_type String, size Int16),\nrepo Tuple(id Int32, name String, url String), type String)\n")),(0,s.kt)("p",null,"The most interesting component of this mapping is the handling of the nested JSON. Note how the JSON structure below is mapped to ",(0,s.kt)("inlineCode",{parentName:"p"},"repo Tuple(id Int32, name String, url String)"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'  "repo": {\n    "id": 429298592,\n    "name": "revacprogramming/pps-test1-Lakshmipatil2021",\n    "url": "https://api.github.com/repos/revacprogramming/pps-test1-Lakshmipatil2021"\n  }\n')),(0,s.kt)("p",null,"This structure could be mapped manually but would require the user to structure data appropriate for insertion and adapt queries to utilize - see ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches"},"Other Approaches"),", significantly complicating usage."),(0,s.kt)("p",null,"At this point, we are ready to exploit these dynamically created columns with queries."),(0,s.kt)("h3",{id:"selecting-dynamic-subcolumns"},"Selecting Dynamic Subcolumns"),(0,s.kt)("p",null,"Querying the above table highlights some of the ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches"},"historical challenges")," of using Tuples for nested JSON data."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT event.type, event.repo, event.actor FROM github_json LIMIT 1;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"event.type"),(0,s.kt)("th",{parentName:"tr",align:"left"},"event.repo"),(0,s.kt)("th",{parentName:"tr",align:"left"},"event.actor"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"PushEvent"),(0,s.kt)("td",{parentName:"tr",align:"left"},"(","429298592,'revacprogramming/pps-test1-Lakshmipatil2021','",(0,s.kt)("a",{parentName:"td",href:"https://api.github.com/repos/revacprogramming/pps-test1-Lakshmipatil2021'%5C"},"https://api.github.com/repos/revacprogramming/pps-test1-Lakshmipatil2021'\\"),")"),(0,s.kt)("td",{parentName:"tr",align:"left"},"(","'",(0,s.kt)("a",{parentName:"td",href:"https://avatars.githubusercontent.com/u/93110249?','Lakshmipatil2021','',93110249,'Lakshmipatil2021','https://api.github.com/users/Lakshmipatil2021'%5C"},"https://avatars.githubusercontent.com/u/93110249?','Lakshmipatil2021','',93110249,'Lakshmipatil2021','https://api.github.com/users/Lakshmipatil2021'\\"),")")))),(0,s.kt)("p",null,"To return the original structure we need both JSONEachRow format and the parameter ",(0,s.kt)("inlineCode",{parentName:"p"},"output_format_json_named_tuples_as_objects"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT event.type, event.repo, event.actor FROM github_json LIMIT 1\nFORMAT JSONEachRow SETTINGS output_format_json_named_tuples_as_objects=1;\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{"event.type":"PushEvent","event.repo":{"id":429298592,\n"name":"revacprogramming\\/pps-test1-Lakshmipatil2021",\n"url":"https:\\/\\/api.github.com\\/repos\\/revacprogramming\\/pps-test1-Lakshmipatil2021"},\n"event.actor":{"avatar_url":"https:\\/\\/avatars.githubusercontent.com\\/u\\/93110249?",\n"display_login":"Lakshmipatil2021","gravatar_id":"","id":93110249,\n"login":"Lakshmipatil2021","url":"https:\\/\\/api.github.com\\/users\\/Lakshmipatil2021"}}\n')),(0,s.kt)("p",null,"While the above-simplified example illustrates the mechanics of using JSON Object types, users need to query these JSON-based columns using the same filters and aggregation capabilities as any other type. We can translate some of the examples provided here to JSON queries to illustrate equivalence. Note this is a 1m row sample of data only, so results are meaningless."),(0,s.kt)("p",null,"Counting the ",(0,s.kt)("a",{parentName:"p",href:"https://ghe.clickhouse.tech/#top-repositories-by-stars"},"top repositories by stars")," becomes a simple query. Note the use of a period as a path delimiter in nested objects:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT event.repo.name, count() AS stars FROM github_json WHERE event.type = 'WatchEvent'\nGROUP BY event.repo.name ORDER BY stars DESC LIMIT 5;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"event.repo.name"),(0,s.kt)("th",{parentName:"tr",align:"left"},"stars"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"dwmkerr/hacker-laws"),(0,s.kt)("td",{parentName:"tr",align:"left"},"283")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"tkellogg/dura"),(0,s.kt)("td",{parentName:"tr",align:"left"},"200")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"aplus-framework/app"),(0,s.kt)("td",{parentName:"tr",align:"left"},"157")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"seemoo-lab/opendrop"),(0,s.kt)("td",{parentName:"tr",align:"left"},"111")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"heroku-python/flask-sockets"),(0,s.kt)("td",{parentName:"tr",align:"left"},"92")))),(0,s.kt)("p",null,"More complex queries ",(0,s.kt)("a",{parentName:"p",href:"https://ghe.clickhouse.tech/#how-has-the-list-of-top-repositories-changed-over-the-years"},"showing the list of top repositories over time")," are also possible. We adapt the query as it covers a short period (3 days). Also, note the need to parse the ",(0,s.kt)("inlineCode",{parentName:"p"},"event.created_at field")," with the function ",(0,s.kt)("inlineCode",{parentName:"p"},"parseDateTimeBestEffort")," as this has been inferred as a string."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n   repo AS name,\n   groupArrayInsertAt(toUInt32(c), toUInt64(dateDiff('hour', toDate('2022-01-01'), hour))) AS data\nFROM\n(\n   SELECT\n       lower(event.repo.name) AS repo,\n       toStartOfHour(parseDateTimeBestEffort(event.created_at)) AS hour,\n       count() AS c\n   FROM github_json\n   WHERE (event.type = 'WatchEvent') AND (toYear(parseDateTimeBestEffort(event.created_at)) >= 2022) AND (repo IN\n   (\n       SELECT lower(event.repo.name) AS repo\n       FROM github_json\n       WHERE (event.type = 'WatchEvent') AND (toYear(parseDateTimeBestEffort(event.created_at)) >= 2022)\n       GROUP BY event.repo.name\n       ORDER BY count() DESC\n       LIMIT 10\n   ))\n   GROUP BY\n       repo,\n       hour\n)\nGROUP BY repo\nORDER BY repo ASC;\n")),(0,s.kt)("h3",{id:"adding-primary-keys"},"Adding Primary Keys"),(0,s.kt)("p",null,"The above example is not realistic in that it has no primary or sort key i.e., it uses ",(0,s.kt)("inlineCode",{parentName:"p"},"tuple()"),". This negates the benefit of the index features in ClickHouse. To add a primary key, and still exploit the JSON object capabilities, we recommended using a dedicated subkey for the JSON. This requires inserting the data using the JSONEachRow format instead of JSONAsObject. For example, consider the JSON below and the corresponding table definition and insert statement."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET allow_experimental_object_type=1;\n\nDROP TABLE IF EXISTS github_json;\n\nCREATE table github_json\n(\n   event_type Enum('CommitCommentEvent' = 1, 'CreateEvent' = 2, 'DeleteEvent' = 3,\n   'ForkEvent' = 4, 'GollumEvent' = 5, 'IssueCommentEvent' = 6, 'IssuesEvent' = 7, 'MemberEvent' = 8,\n   'PublicEvent' = 9, 'PullRequestEvent' = 10, 'PullRequestReviewCommentEvent' = 11,\n   'PushEvent' = 12, 'ReleaseEvent' = 13, 'SponsorshipEvent' = 14, 'WatchEvent' = 15, 'GistEvent' = 16, 'FollowEvent' = 17, 'DownloadEvent' = 18, 'PullRequestReviewEvent' = 19,\n   'ForkApplyEvent' = 20, 'Event' = 21, 'TeamAddEvent' = 22),\n    repo_name LowCardinality(String),\n    event      JSON\n) ENGINE = MergeTree ORDER BY (event_type, repo_name);\n")),(0,s.kt)("p",null,"Inserting data requires us to use the JSONEachRow format. Note how the ",(0,s.kt)("inlineCode",{parentName:"p"},"event")," sub field now holds our dynamic JSON, whilst the root keys are explicitly defined."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_json FORMAT JSONEachRow\n{"event":{"type":"PushEvent","actor":{"avatar_url":"https://avatars.githubusercontent.com/u/41898282?",\n"display_login":"github-actions","gravatar_id":"","id":41898282,"login":"github-actions[bot]",\n"url":"https://api.github.com/users/github-actions[bot]"},"repo":{"id":410071248,\n"name":"pioug/yield-data","url":"https://api.github.com/repos/pioug/yield-data"}},\n"event_type":"PushEvent","repo_name":"pioug/yield-data"}\n')),(0,s.kt)("p",null,"This requires a restructuring of our JSON, which is inconvenient at best. Ideally, we need a more flexible approach that allows us to modify the fields we wish to extract as root keys over time without needing to change our data pipelines. Inserting our row as a ",(0,s.kt)("inlineCode",{parentName:"p"},"String")," inside an EPHEMERAL column ",(0,s.kt)("inlineCode",{parentName:"p"},"message_raw"),", we can extract specific fields of interest using DEFAULT expressions for the root fields. The ",(0,s.kt)("inlineCode",{parentName:"p"},"String")," EPHEMERAL column is also mapped to a JSON object column ",(0,s.kt)("inlineCode",{parentName:"p"},"message")," that provides the usual flexibility. This ",(0,s.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/sql-reference/statements/create/table/#ephemeral"},"EPHEMERAL")," column will not be persisted and will be discarded at INSERT time. Our primary key fields are as a result duplicated i.e. they occur at the root of the document, as well as in the ",(0,s.kt)("inlineCode",{parentName:"p"},"message")," JSON."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS github_json;\n\nSET allow_experimental_object_type = 1;\nCREATE table github_json\n(\n   event_type LowCardinality(String) DEFAULT JSONExtractString(message_raw, 'type'),\n   repo_name LowCardinality(String) DEFAULT JSONExtractString(message_raw, 'repo.name'),\n   message JSON DEFAULT message_raw,\n   message_raw String EPHEMERAL\n) ENGINE = MergeTree ORDER BY (event_type, repo_name);\n")),(0,s.kt)("p",null,"Insertion thus requires a modified structure - note how the JSON is parsed as a string inside message_raw."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_json (message_raw) FORMAT JSONEachRow {"message_raw": "{\\"type\\":\\"PushEvent\\",\n\\"created_at\\": \\"2022-01-04 07:00:00\\", \\"actor\\":{\\"avatar_url\\":\\"https://avatars.githubusercontent.com/u/41898282?\\",\n\\"display_login\\":\\"github-actions\\",\\"gravatar_id\\":\\"\\",\\"id\\":41898282,\\"login\\":\\"github-actions[bot]\\",\n\\"url\\":\\"https://api.github.com/users/github-actions[bot]\\"},\\"repo\\":{\\"id\\":410071248,\\"name\\":\\"pioug/yield-data\\",\n\\"url\\":\\"https://api.github.com/repos/pioug/yield-data\\"}}"}\n')),(0,s.kt)("p",null,"To add fields to the root, we in turn just need to ALTER the table definition adding fields as required. For details on how to retrospectively add columns, see the technique used in ",(0,s.kt)("a",{parentName:"p",href:"#other-approaches#hybrid-approach-with-materialized-columns"},"Other Approaches"),"."),(0,s.kt)("h3",{id:"limitations-and-best-practices"},"Limitations and Best Practices"),(0,s.kt)("p",null,"Dynamic columns in JSON objects are as fast predefined types. The flexible schema is an extremely powerful feature at every little syntax overhead and a natural fit for handling data such as logs - where keys are frequently added through dynamic properties such as container labels in Kubernetes."),(0,s.kt)("p",null,"Parsing of JSON, and inference of the schema does incur a cost at insertion time. Because of this, we recommend keeping column counts below 10k. Should you need to exceed this, consult",(0,s.kt)("a",{parentName:"p",href:"https://github.com/ClickHouse/ClickHouse/issues/new?assignees=&labels=question&template=10_question.md&title="}," ClickHouse support"),"."),(0,s.kt)("p",null,"There are also limitations as to how dynamic columns can be used. As noted earlier, they cannot be used as primary or sort keys. Furthermore, they cannot be configured to use specific codecs. For optimal performance, we recommend the JSON object type be used for a specific subkey of the JSON and the root keys be declared explicitly. This allows them to be configured with specific codecs or used for sort/primary keys. As shown in ",(0,s.kt)("a",{parentName:"p",href:"#adding-primary-keys"},"Adding Primary Keys"),", this requires the use of the JSONEachRow format vs. inserting the entire row as JSON with the JSONAsObject format."),(0,s.kt)("h3",{id:"handling-data-changes"},"Handling Data Changes"),(0,s.kt)("h4",{id:"adding-columns"},"Adding Columns"),(0,s.kt)("p",null,"Handling semi-structured data requires ClickHouse to adapt new columns as they are added or their type changes. We explore some of these behaviors below."),(0,s.kt)("p",null,"Consider the simple example below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "type": "PushEvent",\n  "actor": {\n    "id": 93110249\n  },\n  "repo": {\n    "id": 429298592,\n    "name": "revacprogramming/pps-test1-Lakshmipatil2021",\n    "url": "https://api.github.com/repos/revacprogramming/pps-test1-Lakshmipatil2021"\n  }\n}\n')),(0,s.kt)("p",null,"Creating a table to accept this data and performing the insert is trivial."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'SET allow_experimental_object_type=1;\nCREATE table github_tmp (event JSON) ENGINE = MergeTree ORDER BY tuple();\n\nINSERT INTO github_tmp FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":93110249},"repo":{"id":429298592,\n"name":"revacprogramming/pps-test1-Lakshmipatil2021",\n"url":"https://api.github.com/repos/revacprogramming/pps-test1-Lakshmipatil2021"}}\n')),(0,s.kt)("p",null,"Inspecting the types we can see the columns created:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET describe_extend_object_types=1;\nDESCRIBE github_tmp;\n\nTuple(actor Tuple(id Int32), repo Tuple(id Int32, name String, url String), type String)\n")),(0,s.kt)("p",null,"Suppose now we insert the following object. This adds additional fields to the actor object:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "type": "PushEvent",\n    "actor": {\n      "avatar_url": "https://avatars.githubusercontent.com/u/81258380?",\n      "display_login": "Helikopter-Bojowy",\n      "gravatar_id": "",\n      "id": 81258380,\n      "login": "Helikopter-Bojowy",\n      "url": "https://api.github.com/users/Helikopter-Bojowy"\n    },\n    "repo": {\n      "id": 352069365,\n      "name": "Helikopter-Bojowy/Exp-na-helikopterze",\n      "url": "https://api.github.com/repos/Helikopter-Bojowy/Exp-na-helikopterze"\n    }\n}\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_tmp FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"avatar_url":"https://avatars.githubusercontent.com/u/81258380?",\n"display_login":"Helikopter-Bojowy","gravatar_id":"","id":81258380,"login":"Helikopter-Bojowy",\n"url":"https://api.github.com/users/Helikopter-Bojowy"},"repo":{"id":352069365,\n"name":"Helikopter-Bojowy/Exp-na-helikopterze",\n"url":"https://api.github.com/repos/Helikopter-Bojowy/Exp-na-helikopterze"}}\n')),(0,s.kt)("p",null,"If we inspect the schema, we can see the columns have automatically been inferred and added:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET describe_extend_object_types=1;\nDESCRIBE github_tmp;\n\nTuple(actor Tuple(avatar_url String, display_login String, gravatar_id String,\nid Int32, login String, url String), repo Tuple(id Int32, name String, url String),\ntype String)\n")),(0,s.kt)("h4",{id:"changing-columns"},"Changing Columns"),(0,s.kt)("p",null,"Despite best efforts, JSON is often inconsistent in types. Whilst some data stores, such as Kafka, can enforce a schema on JSON this is often not enforced. As a result, ClickHouse can receive the same field in multiple types. This often requires unifying types. Consider the following example:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "type": "PushEvent",\n  "actor": {\n    "id": 10\n  }\n}\n')),(0,s.kt)("p",null,"Here ",(0,s.kt)("inlineCode",{parentName:"p"},"actor.id")," is an integer. If inserted to a table, it will be mapped to an Int8 as shown below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'SET allow_experimental_object_type=1;\nCREATE table github_types ( event JSON ) ENGINE = MergeTree ORDER BY tuple();\n\nINSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":10}}\n\nSET describe_extend_object_types=1;\nDESCRIBE github_types;\n\nTuple(actor Tuple(id Int8), type String)\n')),(0,s.kt)("p",null,"Now Github has alot more users than can be represented by an Int8. A typical user id is much larger. Consider the more realistic example below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":93110249}}\n')),(0,s.kt)("p",null,"As shown the id field is now represented as an Int32."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET describe_extend_object_types=1;\nDESCRIBE github_types;\n\nTuple(actor Tuple(id Int32), type String)\n")),(0,s.kt)("p",null,"Suppose that Github decides that ids can be alphanumeric, or more realistic a value is inserted as a string e.g."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "type": "PushEvent",\n    "actor": {\n      "id": "81258380"\n    }\n}\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":"81258380"}}\n\nSET describe_extend_object_types=1;\nDESCRIBE github_types;\n\nTuple(actor Tuple(id String), type String)\n')),(0,s.kt)("p",null,"As shown, ClickHouse is now forced to represent the ",(0,s.kt)("inlineCode",{parentName:"p"},"actor.id")," column as a string."),(0,s.kt)("p",null,"This sort of coercion is supported for most types that have variable representation e.g. Int, Float. If necessary, ClickHouse will unify to the higher bit type that allows all current values to be represented. If necessary, converting to a ",(0,s.kt)("inlineCode",{parentName:"p"},"String")," represents the least precise definition."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Warning: This changing in types can break queries if you rely on type specific functions e.g. sum for numerics. We recommend you ensure your data is consistent where possible and rely on this feature as a backup vs best practice.")),(0,s.kt)("p",null,"Note that not all types can be unified. Attempting the following, after inserting any of the previous data will result in an error:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":["92258380"]}}\n')),(0,s.kt)("p",null,"The inverse of this would also fail i.e. if for the first row id was an ",(0,s.kt)("inlineCode",{parentName:"p"},"Array(String)")," and subsequent rows were only a ",(0,s.kt)("inlineCode",{parentName:"p"},"String"),". Likewise objects (represented as Tuples) cannot be unified with scalar types such as ",(0,s.kt)("inlineCode",{parentName:"p"},"String"),". The contents of these can, however, be coerced. For example, consider the following where actor.id is first an ",(0,s.kt)("inlineCode",{parentName:"p"},"Array(Int8)")," and then an ",(0,s.kt)("inlineCode",{parentName:"p"},"Array(String)"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'DROP TABLE github_types;\nSET allow_experimental_object_type=1;\nCREATE table github_types ( event JSON ) ENGINE = MergeTree ORDER BY tuple();\n\nINSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":[10]}}\n\nSET describe_extend_object_types=1;\nDESCRIBE github_types;\n\nTuple(actor Tuple(id Array(Int8)), type String)\n\nINSERT INTO github_types FORMAT JSONAsObject\n{"type":"PushEvent","actor":{"id":["92258380"]}}\n\nSET describe_extend_object_types=1;\nDESCRIBE github_types;\n\nTuple(actor Tuple(id Array(String)), type String)\n')),(0,s.kt)("h3",{id:"handling-json-formats"},"Handling JSON Formats"),(0,s.kt)("p",null,"ClickHouse can handle JSON in a number of formats, other than JSONEachRow and JSONAsObject. These are useful on both input and output and are described ",(0,s.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/interfaces/formats/#json"},"here"),"."),(0,s.kt)("h2",{id:"importing-and-exporting-json-data-in-clickhouse"},"Importing and exporting JSON data in ClickHouse"),(0,s.kt)("p",null,"JSON is a popular format for exchanging data between different layers of modern applications. ClickHouse provides many tuning options to support almost any form of JSON data."),(0,s.kt)("h3",{id:"importing-json-data"},"Importing JSON data"),(0,s.kt)("p",null,"To import JSON data, we first have to define which JSON type to use. This will depend on how the input data is structured."),(0,s.kt)("admonition",{title:"JSON tutorial",type:"tip"},(0,s.kt)("p",{parentName:"admonition"},"For a step by step tutorial with a large JSON dataset, please see ",(0,s.kt)("a",{parentName:"p",href:"#loading-json-in-5-steps"},"Loading JSON in 5 steps"),".")),(0,s.kt)("h4",{id:"importing-from-an-array-of-json-objects"},"Importing from an array of JSON objects"),(0,s.kt)("p",null,"One of the most popular forms of JSON data is having a list of JSON objects in a JSON array, like in ",(0,s.kt)("a",{target:"_blank",href:a(19239).Z},"this example"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'> cat list.json\n[\n  {\n    "path": "Akiba_Hebrew_Academy",\n    "month": "2017-08-01",\n    "hits": 241\n  },\n  {\n    "path": "Aegithina_tiphia",\n    "month": "2018-02-01",\n    "hits": 34\n  },\n  ...\n]\n')),(0,s.kt)("p",null,"Let\u2019s create a table for this kind of data:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE sometable\n(\n    `path` String,\n    `month` Date,\n    `hits` UInt32\n)\nENGINE = MergeTree\nORDER BY tuple(month, path)\n")),(0,s.kt)("p",null,"To import a list of JSON objects, we can use a ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoneachrow"},"JSONEachRow")," format (inserting data from ",(0,s.kt)("a",{target:"_blank",href:a(19239).Z},"list.json")," file):"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO sometable\nFROM INFILE 'list.json'\nFORMAT JSONEachRow\n")),(0,s.kt)("p",null,"We have used a ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/insert-into/#inserting-data-from-a-file"},"FROM INFILE")," clause to load data from the local file, and we can see import was successful:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM sometable\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 1971-72_Utah_Stars_season \u2502 2016-10-01 \u2502    1 \u2502\n\u2502 Akiba_Hebrew_Academy      \u2502 2017-08-01 \u2502  241 \u2502\n\u2502 Aegithina_tiphia          \u2502 2018-02-01 \u2502   34 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h5",{id:"handling-ndjson-line-delimited-json"},"Handling NDJSON (line delimited JSON)"),(0,s.kt)("p",null,"Many apps can log data in JSON format so that each log line is an individual JSON object, like in ",(0,s.kt)("a",{target:"_blank",href:a(43817).Z},"this file"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"cat object-per-line.json\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{"path":"1-krona","month":"2017-01-01","hits":4}\n{"path":"Ahmadabad-e_Kalij-e_Sofla","month":"2017-01-01","hits":3}\n{"path":"Bob_Dolman","month":"2016-11-01","hits":245}\n')),(0,s.kt)("p",null,"The same ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONEachRow")," format is capable of working with such files:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO sometable FROM INFILE 'object-per-line.json' FORMAT JSONEachRow;\nSELECT * FROM sometable;\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 Bob_Dolman                \u2502 2016-11-01 \u2502  245 \u2502\n\u2502 1-krona                   \u2502 2017-01-01 \u2502    4 \u2502\n\u2502 Ahmadabad-e_Kalij-e_Sofla \u2502 2017-01-01 \u2502    3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h4",{id:"importing-from-json-object-keys"},"Importing from JSON object keys"),(0,s.kt)("p",null,"In some cases, the list of JSON objects can be encoded as object properties instead of array elements (see ",(0,s.kt)("a",{target:"_blank",href:a(40743).Z},"objects.json")," for example):"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"cat objects.json\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{\n  "a": {\n    "path":"April_25,_2017",\n    "month":"2018-01-01",\n    "hits":2\n  },\n  "b": {\n    "path":"Akahori_Station",\n    "month":"2016-06-01",\n    "hits":11\n  },\n  ...\n}\n')),(0,s.kt)("p",null,"ClickHouse can load data from this kind of data using ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsonobjecteachrow"},"JSONObjectEachRow")," format:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO sometable FROM INFILE 'objects.json' FORMAT JSONObjectEachRow;\nSELECT * FROM sometable;\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 Abducens_palsy  \u2502 2016-05-01 \u2502   28 \u2502\n\u2502 Akahori_Station \u2502 2016-06-01 \u2502   11 \u2502\n\u2502 April_25,_2017  \u2502 2018-01-01 \u2502    2 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h5",{id:"importing-parent-object-key-values"},"Importing parent object key values"),(0,s.kt)("p",null,"Let\u2019s say we also want to save values in parent object keys to the table. In this case, we can use the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/operations/settings/formats/#format_json_object_each_row_column_for_object_name"},"following option")," to define the name of the column we want key values to be saved to:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET format_json_object_each_row_column_for_object_name = 'id'\n")),(0,s.kt)("p",null,"Now we can check which data is going to be loaded from the original JSON file using ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/files/#file"},"file()")," function:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM file('objects.json', JSONObjectEachRow)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500id\u2500\u252c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 a  \u2502 April_25,_2017  \u2502 2018-01-01 \u2502    2 \u2502\n\u2502 b  \u2502 Akahori_Station \u2502 2016-06-01 \u2502   11 \u2502\n\u2502 c  \u2502 Abducens_palsy  \u2502 2016-05-01 \u2502   28 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"Note how the ",(0,s.kt)("inlineCode",{parentName:"p"},"id")," column has been populated by key values correctly."),(0,s.kt)("h4",{id:"importing-from-json-arrays"},"Importing from JSON arrays"),(0,s.kt)("p",null,"Sometimes, for the sake of saving space, JSON files are encoded in arrays instead of objects. In this case, we deal with a ",(0,s.kt)("a",{target:"_blank",href:a(61268).Z},"list of JSON arrays"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"cat arrays.json\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'["Akiba_Hebrew_Academy", "2017-08-01", 241],\n["Aegithina_tiphia", "2018-02-01", 34],\n["1971-72_Utah_Stars_season", "2016-10-01", 1]\n')),(0,s.kt)("p",null,"In this case, ClickHouse will load this data and attribute each value to the corresponding column based on its order in the array. We use ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncompacteachrow"},"JSONCompactEachRow")," format for this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 1971-72_Utah_Stars_season \u2502 2016-10-01 \u2502    1 \u2502\n\u2502 Akiba_Hebrew_Academy      \u2502 2017-08-01 \u2502  241 \u2502\n\u2502 Aegithina_tiphia          \u2502 2018-02-01 \u2502   34 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h4",{id:"importing-individual-columns-from-json-arrays"},"Importing individual columns from JSON arrays"),(0,s.kt)("p",null,"In some cases, data can be encoded column-wise instead of row-wise. In this case, a parent JSON object contains columns with values. Take a look at the ",(0,s.kt)("a",{target:"_blank",href:a(1996).Z},"following file"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"cat columns.json\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{\n  "path": ["2007_Copa_America", "Car_dealerships_in_the_USA", "Dihydromyricetin_reductase"],\n  "month": ["2016-07-01", "2015-07-01", "2015-07-01"],\n  "hits": [178, 11, 1]\n}\n')),(0,s.kt)("p",null,"ClickHouse uses ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncolumns"},"JSONColumns")," format to parse data formatted like that:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM file('columns.json', JSONColumns)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 2007_Copa_America          \u2502 2016-07-01 \u2502  178 \u2502\n\u2502 Car_dealerships_in_the_USA \u2502 2015-07-01 \u2502   11 \u2502\n\u2502 Dihydromyricetin_reductase \u2502 2015-07-01 \u2502    1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"A more compact format is also supported when dealing with an ",(0,s.kt)("a",{target:"_blank",href:a(11638).Z},"array of columns")," instead of an object using ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncompactcolumns"},"JSONCompactColumns")," format:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM file('columns-array.json', JSONCompactColumns)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500c1\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500c2\u2500\u252c\u2500c3\u2500\u2510\n\u2502 Heidenrod       \u2502 2017-01-01 \u2502 10 \u2502\n\u2502 Arthur_Henrique \u2502 2016-11-01 \u2502 12 \u2502\n\u2502 Alan_Ebnother   \u2502 2015-11-01 \u2502 66 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h4",{id:"saving-json-objects-instead-of-parsing"},"Saving JSON objects instead of parsing"),(0,s.kt)("p",null,"There are cases you might want to save JSON objects to a single String (or JSON) column instead of parsing it. This can be useful when dealing with a list of JSON objects of different structures. Let\u2019s take ",(0,s.kt)("a",{target:"_blank",href:a(46287).Z},"this file"),", where we have multiple different JSON objects inside a parent list:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"cat custom.json\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'[\n  {"name": "Joe", "age": 99, "type": "person"},\n  {"url": "/my.post.MD", "hits": 1263, "type": "post"},\n  {"message": "Warning on disk usage", "type": "log"}\n]\n')),(0,s.kt)("p",null,"We want to save original JSON objects into the following table:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE events\n(\n    `data` String\n)\nENGINE = MergeTree\nORDER BY ()\n")),(0,s.kt)("p",null,"Now we can load data from the file into this table using ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsonasstring"},"JSONAsString")," format to keep JSON objects instead of parsing them:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO events (data)\nFROM INFILE 'custom.json'\nFORMAT JSONAsString\n")),(0,s.kt)("p",null,"And we can use ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/json-functions"},"JSON functions")," to query saved objects:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    JSONExtractString(data, 'type') AS type,\n    data\nFROM events\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'\u250c\u2500type\u2500\u2500\u2500\u252c\u2500data\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 person \u2502 {"name": "Joe", "age": 99, "type": "person"}         \u2502\n\u2502 post   \u2502 {"url": "/my.post.MD", "hits": 1263, "type": "post"} \u2502\n\u2502 log    \u2502 {"message": "Warning on disk usage", "type": "log"}  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n')),(0,s.kt)("p",null,"Consider using ",(0,s.kt)("a",{parentName:"p",href:"#json-as-object"},"JSONAsObject")," together with a new ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/json"},"JSON data type")," to store and process JSON in tables in a more efficient way. Note that JSONAsString works perfectly fine in cases we have JSON object-per-line formatted files (usually used with ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONEachRow")," format)."),(0,s.kt)("h3",{id:"data-types-detection-when-importing-json-data"},"Data types detection when importing JSON data"),(0,s.kt)("p",null,"ClickHouse does some magic to guess the best types while importing JSON data. We can use a ",(0,s.kt)("inlineCode",{parentName:"p"},"DESCRIBE")," clause to check which types were defined:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE TABLE file('list.json', JSONEachRow)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500name\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u252c\u2500comment\u2500\u252c\u2500codec_expression\u2500\u252c\u2500ttl_expression\u2500\u2510\n\u2502 path  \u2502 Nullable(String) \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 month \u2502 Nullable(Date)   \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 hits  \u2502 Nullable(Int64)  \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"This allows quickly creating tables from JSON files:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE new_table\nENGINE = MergeTree\nORDER BY tuple() AS\nSELECT *\nFROM file('list.json', JSONEachRow)\n")),(0,s.kt)("p",null,"Detected types will be used for this table:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DESCRIBE TABLE new_table\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500name\u2500\u2500\u252c\u2500type\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500default_type\u2500\u252c\u2500default_expression\u2500\u252c\u2500comment\u2500\u252c\u2500codec_expression\u2500\u252c\u2500ttl_expression\u2500\u2510\n\u2502 path  \u2502 Nullable(String) \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 month \u2502 Nullable(Date)   \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2502 hits  \u2502 Nullable(Int64)  \u2502              \u2502                    \u2502         \u2502                  \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("h3",{id:"json-objects-with-nested-objects"},"JSON objects with nested objects"),(0,s.kt)("p",null,"In cases we're dealing with ",(0,s.kt)("a",{target:"_blank",href:a(76678).Z},"nested JSON objects"),", we can additionally define schema and use complex types (",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/array/"},"Array"),", ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/json/"},"JSON")," or ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/tuple/"},"Tuple"),") to load data:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM file('list-nested.json', JSONEachRow, 'page JSON, month Date, hits UInt32')\nLIMIT 1\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'\u250c\u2500page\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 {"owner_id":12,"path":"Akiba_Hebrew_Academy","title":"Akiba Hebrew Academy"} \u2502 2017-08-01 \u2502  241 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n')),(0,s.kt)("h4",{id:"nested-json-objects"},"Nested JSON objects"),(0,s.kt)("p",null,"We can refer to nested JSON keys by enabling the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/operations/settings/formats/#input_format_import_nested_json"},"following settings option"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET input_format_import_nested_json = 1\n")),(0,s.kt)("p",null,"This allows us to refer to nested JSON object keys using dot notation (remember to wrap those with backtick symbols to work):"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM file('list-nested.json', JSONEachRow, '`page.owner_id` UInt32, `page.title` String, month Date, hits UInt32')\nLIMIT 1\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-results"},"\u250c\u2500page.owner_id\u2500\u252c\u2500page.title\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502            12 \u2502 Akiba Hebrew Academy \u2502 2017-08-01 \u2502  241 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"This way, we can flatten nested JSON objects or use some nested values to save them as separate columns."),(0,s.kt)("h3",{id:"skipping-unknown-columns"},"Skipping unknown columns"),(0,s.kt)("p",null,"By default, ClickHouse will ignore unknown columns when importing JSON data. Let\u2019s try to import the original file into the table without the ",(0,s.kt)("inlineCode",{parentName:"p"},"month")," column:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE shorttable\n(\n    `path` String,\n    `hits` UInt32\n)\nENGINE = MergeTree\nORDER BY path\n")),(0,s.kt)("p",null,"We can still insert the ",(0,s.kt)("a",{target:"_blank",href:a(19239).Z},"original JSON data")," with 3 columns into this table:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO shorttable FROM INFILE 'list.json' FORMAT JSONEachRow;\nSELECT * FROM shorttable\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500hits\u2500\u2510\n\u2502 1971-72_Utah_Stars_season \u2502    1 \u2502\n\u2502 Aegithina_tiphia          \u2502   34 \u2502\n\u2502 Akiba_Hebrew_Academy      \u2502  241 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"ClickHouse will ignore unknown columns while importing. This can be disabled with the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/operations/settings/formats/#input_format_skip_unknown_fields"},"input_format_skip_unknown_fields")," settings option:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET input_format_skip_unknown_fields = 0;\nINSERT INTO shorttable FROM INFILE 'list.json' FORMAT JSONEachRow;\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"Ok.\nException on client:\nCode: 117. DB::Exception: Unknown field found while parsing JSONEachRow format: month: (in file/uri /data/clickhouse/user_files/list.json): (at row 1)\n")),(0,s.kt)("p",null,"ClickHouse will throw exceptions in cases of inconsistent JSON and table columns structure."),(0,s.kt)("h3",{id:"exporting-json-data"},"Exporting JSON data"),(0,s.kt)("p",null,"Almost any JSON format used for import can be used for export as well. The most popular is ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoneachrow"},"JSONEachRow"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{"path":"Bob_Dolman","month":"2016-11-01","hits":245}\n{"path":"1-krona","month":"2017-01-01","hits":4}\n{"path":"Ahmadabad-e_Kalij-e_Sofla","month":"2017-01-01","hits":3}\n')),(0,s.kt)("p",null,"Or we can use JSONCompactEachRow to save disk space by skipping column names:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONCompactEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'["Bob_Dolman", "2016-11-01", 245]\n["1-krona", "2017-01-01", 4]\n["Ahmadabad-e_Kalij-e_Sofla", "2017-01-01", 3]\n')),(0,s.kt)("h4",{id:"overriding-data-types-as-strings"},"Overriding data types as strings"),(0,s.kt)("p",null,"ClickHouse respects data types and will export JSON accordingly to standards. But in cases we need to have all values encoded as strings, we can use ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsonstringseachrow"},"JSONStringsEachRow")," format:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONStringsEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{"path":"Bob_Dolman","month":"2016-11-01","hits":"245"}\n{"path":"1-krona","month":"2017-01-01","hits":"4"}\n{"path":"Ahmadabad-e_Kalij-e_Sofla","month":"2017-01-01","hits":"3"}\n')),(0,s.kt)("p",null,"Now ",(0,s.kt)("inlineCode",{parentName:"p"},"hits")," numeric column is encoded as a string. Exporting as strings is supported for all JSON* formats, just explore ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONStrings\\*")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONCompactStrings\\*")," formats:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONCompactStringsEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'["Bob_Dolman", "2016-11-01", "245"]\n["1-krona", "2017-01-01", "4"]\n["Ahmadabad-e_Kalij-e_Sofla", "2017-01-01", "3"]\n')),(0,s.kt)("h4",{id:"exporting-metadata-together-with-data"},"Exporting metadata together with data"),(0,s.kt)("p",null,"General ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#json"},"JSON")," format, which is popular in apps, will export not only resulting data but column types and query stats:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSON\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{\n    "meta":\n    [\n        {\n            "name": "path",\n            "type": "String"\n        },\n        \u2026\n    ],\n\n    "data":\n    [\n        {\n            "path": "Bob_Dolman",\n            "month": "2016-11-01",\n            "hits": 245\n        },\n        \u2026\n    ],\n\n    "rows": 3,\n\n    "statistics":\n    {\n        "elapsed": 0.000497457,\n        "rows_read": 3,\n        "bytes_read": 87\n    }\n}\n')),(0,s.kt)("p",null,"The ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncompact"},"JSONCompact")," format will print the same metadata, but use a compacted form for the data itself:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONCompact\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'{\n    "meta":\n    [\n        {\n            "name": "path",\n            "type": "String"\n        },\n        \u2026\n    ],\n\n    "data":\n    [\n        ["Bob_Dolman", "2016-11-01", 245],\n        ["1-krona", "2017-01-01", 4],\n        ["Ahmadabad-e_Kalij-e_Sofla", "2017-01-01", 3]\n    ],\n\n    "rows": 3,\n\n    "statistics":\n    {\n        "elapsed": 0.00074981,\n        "rows_read": 3,\n        "bytes_read": 87\n    }\n}\n')),(0,s.kt)("p",null,"Consider ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsonstrings"},"JSONStrings")," or ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncompactstrings"},"JSONCompactStrings")," variants to encode all values as strings."),(0,s.kt)("h5",{id:"compact-way-to-export-json-data-and-structure"},"Compact way to export JSON data and structure"),(0,s.kt)("p",null,"A more efficient way to have data, as well as it\u2019s structure, is to use ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#jsoncompacteachrowwithnamesandtypes"},"JSONCompactEachRowWithNamesAndTypes")," format:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable FORMAT JSONCompactEachRowWithNamesAndTypes\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},'["path", "month", "hits"]\n["String", "Date", "UInt32"]\n["Bob_Dolman", "2016-11-01", 245]\n["1-krona", "2017-01-01", 4]\n["Ahmadabad-e_Kalij-e_Sofla", "2017-01-01", 3]\n')),(0,s.kt)("p",null,"This will use a compact JSON format prepended by two header rows with column names and types. This format can then be used to ingest data into another ClickHouse instance (or other apps)."),(0,s.kt)("h4",{id:"exporting-json-to-a-file"},"Exporting JSON to a file"),(0,s.kt)("p",null,"To save exported JSON data to a file, we can use an ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/select/into-outfile"},"INTO OUTFILE")," clause:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable INTO OUTFILE 'out.json' FORMAT JSONEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"36838935 rows in set. Elapsed: 2.220 sec. Processed 36.84 million rows, 1.27 GB (16.60 million rows/s., 572.47 MB/s.)\n")),(0,s.kt)("p",null,"It took ClickHouse only 2 seconds to export almost 37m records to a JSON file. We can also export using a ",(0,s.kt)("inlineCode",{parentName:"p"},"COMPRESSION")," clause to enable compression on the fly:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM sometable INTO OUTFILE 'out.json.gz' FORMAT JSONEachRow\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"36838935 rows in set. Elapsed: 22.680 sec. Processed 36.84 million rows, 1.27 GB (1.62 million rows/s., 56.02 MB/s.)\n")),(0,s.kt)("p",null,"It takes more time to accomplish but generates a much smaller compressed file:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"2.2G    out.json\n576M    out.json.gz\n")),(0,s.kt)("h3",{id:"importing-and-exporting-bson"},"Importing and exporting BSON"),(0,s.kt)("p",null,"ClickHouse allows exporting to and importing data from ",(0,s.kt)("a",{parentName:"p",href:"https://bsonspec.org/"},"BSON")," encoded files. This format is used by some DBMSs, e.g. ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/mongodb/mongo"},"MongoDB")," database."),(0,s.kt)("p",null,"To import BSON data, we use the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats/#bsoneachrow"},"BSONEachRow")," format. Let\u2019s import data from ",(0,s.kt)("a",{target:"_blank",href:a(4670).Z},"this BSON file"),":"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM file('data.bson', BSONEachRow)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-response"},"\u250c\u2500path\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500month\u2500\u252c\u2500hits\u2500\u2510\n\u2502 Bob_Dolman                \u2502 17106 \u2502  245 \u2502\n\u2502 1-krona                   \u2502 17167 \u2502    4 \u2502\n\u2502 Ahmadabad-e_Kalij-e_Sofla \u2502 17167 \u2502    3 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n")),(0,s.kt)("p",null,"And we can also export to BSON files using the same format:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM sometable\nINTO OUTFILE 'out.bson'\nFORMAT BSONEachRow\n")),(0,s.kt)("p",null,"After that, we\u2019ll have our data exported to the ",(0,s.kt)("inlineCode",{parentName:"p"},"out.bson")," file."),(0,s.kt)("h3",{id:"other-formats"},"Other formats"),(0,s.kt)("p",null,"ClickHouse introduces support for many formats, both text, and binary, to cover various scenarios and platforms. Explore more formats and ways to work with them in the following articles:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/en/integrations/data-formats/csv-tsv"},"CSV and TSV formats")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/en/integrations/data-formats/parquet"},"Parquet")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"JSON formats")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/en/integrations/data-formats/templates-regexp"},"Regex and templates")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/en/integrations/data-formats/binary-native"},"Native and binary formats")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/en/integrations/data-formats/sql"},"SQL formats"))),(0,s.kt)("p",null,"And also check ",(0,s.kt)("a",{parentName:"p",href:"https://clickhouse.com/blog/extracting-converting-querying-local-files-with-sql-clickhouse-local"},"clickhouse-local")," - a portable full-featured tool to work on local/remote files without the need for ClickHouse server."),(0,s.kt)("h2",{id:"other-approaches"},"Other Approaches"),(0,s.kt)("p",null,"Versions of ClickHouse before 22.3.1 do not support a JSON Object type, and the JSON Object type is not yet GA. The techniques in the tutorial ",(0,s.kt)("a",{parentName:"p",href:"#loading-json-in-5-steps"},"load JSON in 5 steps")," and this page (except for the method using materialized columns) are GA. The limitations of these methods are discussed below."),(0,s.kt)("p",null,"These approaches can be summarized as follows:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Handle as structured data")," - explicitly map each column and ensure that the table schema is maintained if new data is added. We can exploit the tuple, map and nested data types in this case for nested structures."),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Store as a string "),"- using functions to extract properties at query time or potentially adding materialized columns as needed"),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Utilize the map type - "),"use the Map type to store homogenous key-value pair"),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Utilize paired arrays "),"- store the data as arrays of keys and values")),(0,s.kt)("p",null,"We address each of these below, discussing their benefits and ultimate limitations that resulted in the JSON Object type development."),(0,s.kt)("p",null,"For example, we use a simple logging dataset, a sample of which is shown below. Although the full dataset contains over 200m rows, which the user is free to download, only a sample is used in most cases to ensure queries are responsive."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "@timestamp": 893964617,\n  "clientip": "40.135.0.0",\n  "request": {\n    "method": "GET",\n    "path": "/images/hm_bg.jpg",\n    "version": "HTTP/1.0"\n  },\n  "status": 200,\n  "size": 24736\n}\n')),(0,s.kt)("p",null,"The full dataset is available in s3 as numbered files of the format ",(0,s.kt)("inlineCode",{parentName:"p"},"documents-<01-25>.tar.gz"),". We utilize the first of these files ",(0,s.kt)("inlineCode",{parentName:"p"},"documents-01.tar.gz")," to ensure sample queries execute promptly:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow') LIMIT 1;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"@timestamp"),(0,s.kt)("th",{parentName:"tr",align:"left"},"clientip"),(0,s.kt)("th",{parentName:"tr",align:"left"},"request"),(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"size"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"893964617"),(0,s.kt)("td",{parentName:"tr",align:"left"},"40.135.0.0"),(0,s.kt)("td",{parentName:"tr",align:"left"},"{'method':'GET','path':'/images/hm","_","bg.jpg','version':'HTTP/1.0'}"),(0,s.kt)("td",{parentName:"tr",align:"left"},"200"),(0,s.kt)("td",{parentName:"tr",align:"left"},"24736")))),(0,s.kt)("h3",{id:"handle-as-structured-data"},"Handle as Structured Data"),(0,s.kt)("p",null,"If your JSON has a fixed schema, mapping it to an explicit schema provides the most optimal performance. Specifically, users can control codecs, configure data skipping indexes and utilize columns in primary and sort keys."),(0,s.kt)("p",null,"This approach represents the most optimal means of handling JSON. It is limited in a number of ways, however, specifically:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"JSON values need to be consistent and mappable to columns. If the data is inconsistent or dirty, insert logic will need to be modified."),(0,s.kt)("li",{parentName:"ul"},"All columns and their types must be known upfront. Changes will need to be made to the table should JSON keys be added - prior knowledge of this is required.")),(0,s.kt)("p",null,"For the example above, most of the fields have obvious types. However, we have a few options for the object request field: ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/nested-data-structures/nested"},"nested"),", ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/tuple"},"tuple"),", and ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/tuple-map-functions"},"map")," (assuming no support for JSON objects)."),(0,s.kt)("h4",{id:"using-nested"},"Using Nested"),(0,s.kt)("p",null,"Below we provide an example of using nested."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'CREATE table http\n(\n   `@timestamp` Int32 EPHEMERAL 0,\n   clientip     IPv4,\n   request Nested(method LowCardinality(String), path String, version LowCardinality(String)),\n   status       UInt16,\n   size         UInt32,\n   timestamp    DateTime DEFAULT toDateTime(`@timestamp`)\n) ENGINE = MergeTree() ORDER BY (status, timestamp);\n\nSET input_format_import_nested_json = 1;\nINSERT INTO http (`@timestamp`, clientip, request.method, request.path, request.version, status, size)\nFORMAT JSONEachRow\n   {"@timestamp":897819077,"clientip":"45.212.12.0","request":{"method":["GET"],\n   "path":["/french/images/hm_nav_bar.gif"],"version":["HTTP/1.0"]},"status":200,"size":3305}\n')),(0,s.kt)("p",null,"A few important points to note here:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"We need to use the setting ",(0,s.kt)("inlineCode",{parentName:"p"},"input_format_import_nested_json "),"to insert the JSON as a nested structure. Without this, we are required to flatten the JSON i.e."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO http_uint FORMAT JSONEachRow\n{"@timestamp":897819077,"clientip":"45.212.12.0","request.method":["GET"],\n"request.path":["/french/images/hm_nav_bar.gif"],"request.version":["HTTP/1.0"],\n"status":200,"size":3305}\n'))),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"The nested fields method, path, and version need to be passed as JSON arrays")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"The columns must be specified in INSERT - this is actually because of the EPHEMERAL column ",(0,s.kt)("inlineCode",{parentName:"p"},"@timestamp"),", which requires a type conversion."))),(0,s.kt)("p",null,"Columns can be queried using a dot notation."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT clientip, status, size, `request.method` FROM http WHERE has(request.method, 'GET');\n")),(0,s.kt)("p",null,"Notice how we are required to query ",(0,s.kt)("inlineCode",{parentName:"p"},"request.method")," as an Array. It is easiest to think of a nested data structure as multiple column ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/data-types/array"},"arrays")," of the same length. The fields method, path, and version are all separate Array(Type) columns in effect with one critical constraint: ",(0,s.kt)("strong",{parentName:"p"},"the length of the method, path, and version fields must be the same.")),(0,s.kt)("p",null,"If your nested structure fits this constraint, and you are comfortable ensuring the values are inserted as strings, nested provides a simple means of querying JSON. Note the use of Arrays for the sub-columns means the full breath ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/array-functions"},"Array functions")," can potentially be exploited, including the ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/select/array-join"},"Array Join")," clause - useful if your columns have multiple values. Additionally, nested fields can be used in primary and sort keys."),(0,s.kt)("p",null,"Given the constraints and input format for the JSON, we insert our sample dataset using the following query. Note the use of the map operators to access the request fields - this results from schema inference detecting a map for the request field in the s3 data."),(0,s.kt)("p",null,"The following statement inserts 10m rows, so this may take a few minutes to execute. Apply a LIMIT if required."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http (`@timestamp`, clientip, request.method, request.path, request.version, status, size)\nSELECT `@timestamp`, clientip, [request['method']], [request['path']], [request['version']], status,\nsize FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow');\n")),(0,s.kt)("p",null,"Querying this data requires us to access the request fields as arrays. Below we summarize the errors and http methods over a fixed time period."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT status, request.method[1] as method, count() as c\nFROM http\nWHERE status >= 400\n  AND timestamp BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status\nORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"c"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"11267")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"HEAD"),(0,s.kt)("td",{parentName:"tr",align:"left"},"276")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"160")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"POST"),(0,s.kt)("td",{parentName:"tr",align:"left"},"115")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"400"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"81")))),(0,s.kt)("h4",{id:"using-tuples"},"Using Tuples"),(0,s.kt)("p",null,"The nested object request can also be represented as a Tuple. This provides comparable functionality to nested, addressing some of its constraints at the expense of other limitations. For example, by not using Arrays we do not have the same constraint that subfields of an object have to be the same length. This lets us represent more varied structures. However, unlike nested fields, the subfields of tuples cannot be used in primary and sort keys."),(0,s.kt)("p",null,"First, create an example table for the http data:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\n\nCREATE table http\n(\n    `@timestamp` Int32 EPHEMERAL 0,\n    clientip     IPv4,\n    request Tuple(method LowCardinality(String), path String, version LowCardinality(String)),\n    status       UInt16,\n    size         UInt32,\n    timestamp    DateTime DEFAULT toDateTime(`@timestamp`)\n) ENGINE = MergeTree() ORDER BY (status, timestamp);\n")),(0,s.kt)("p",null,"Insertion of data requires changes to the nested field structure. Specifically, note how the \u201crequest\u201d object below must be passed as an array of values."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO http (`@timestamp`, clientip, request, status, size) FORMAT JSONEachRow\n    {"@timestamp":893964617,"clientip":"40.135.0.0","request":["GET", "/images/hm_bg.jpg", "HTTP/1.0"],\n    "status":200,"size":24736}\n')),(0,s.kt)("p",null,"We have minimal data in our example above, but as shown below we can query the tuple fields by their period delimited names. We also aren\u2019t required to use Array functions like nested."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT `request.method`, status, timestamp FROM http WHERE request.method = 'GET';\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"request.method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"timestamp"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"200"),(0,s.kt)("td",{parentName:"tr",align:"left"},"1998-04-30 19:30:17")))),(0,s.kt)("p",null,"The principal disadvantage of tuples, other than the requirement to convert our objects into lists, is the sub fields cannot be used as primary or sort keys. The following will thus fail."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\n\nCREATE table http\n(\n   `@timestamp` Int32 EPHEMERAL 0,\n   clientip     IPv4,\n   request Tuple(method LowCardinality(String), path String, version LowCardinality(String)),\n   status       UInt16,\n   size         UInt32,\n   timestamp    DateTime DEFAULT toDateTime(`@timestamp`)\n) ENGINE = MergeTree() ORDER BY (status, request.method, timestamp);\n")),(0,s.kt)("p",null,"However, the entire tuple can be used for this purpose. The following is valid."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\n\nCREATE table http\n(\n   `@timestamp` Int32 EPHEMERAL 0,\n   clientip     IPv4,\n   request Tuple(method LowCardinality(String), path String, version LowCardinality(String)),\n   status       UInt16,\n   size         UInt32,\n   timestamp    DateTime DEFAULT toDateTime(`@timestamp`)\n) ENGINE = MergeTree() ORDER BY (status, request, timestamp);\n")),(0,s.kt)("p",null,"As noted in ",(0,s.kt)("a",{parentName:"p",href:"#json-semi-structured"},"Semi-Structured Approach"),", the JSON object type available in 22.3 utilizes tuples for nested structures - abstracting the above complexity with a more intuitive query interface."),(0,s.kt)("p",null,"To insert our sample data from s3 we can use the following query. Note the need to form a tuple at insert time for the request field i.e. ",(0,s.kt)("inlineCode",{parentName:"p"},"(request['method'], request['path'], request['version'])"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http(`@timestamp`, clientip, request, status, size) SELECT `@timestamp`, clientip,\n(request['method'], request['path'], request['version']), status, size FROM\ns3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow');\n")),(0,s.kt)("p",null,"To reproduce our earlier query analyzing error rates by status code, we don\u2019t require any special syntax:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"\nSELECT status, request.method as method, count() as c\nFROM http\nWHERE status >= 400\n  AND timestamp BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status\nORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("h4",{id:"using-maps"},"Using Maps"),(0,s.kt)("p",null,"Maps represent a simple way to represent nested structures, with some noticeable limitations:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"The fields must be of all the same type."),(0,s.kt)("li",{parentName:"ul"},"Accessing subfields requires a special map syntax - since the fields don\u2019t exist as columns i.e. the entire object is a column.")),(0,s.kt)("p",null,"Provided we assume the subfields of our request object are all Strings, we use a map to hold this structure."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\nCREATE table http\n(\n   `@timestamp` Int32 EPHEMERAL 0,\n   clientip     IPv4,\n   request Map(String, String),\n   status       UInt16,\n   size         UInt32,\n   timestamp    DateTime DEFAULT toDateTime(`@timestamp`)\n) ENGINE = MergeTree() ORDER BY (status, request, timestamp);\n")),(0,s.kt)("p",null,"Unlike Nested and Tuple, we aren\u2019t required to make changes to our JSON structures at insertion."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO http (`@timestamp`, clientip, request, status, size) FORMAT JSONEachRow\n    {"@timestamp":897819077,"clientip":"45.212.12.0","request":{"method": "GET","path":"/french/images/hm_nav_bar.gif","version":"HTTP/1.1"},"status":200,"size":3305}\n')),(0,s.kt)("p",null,"Querying these fields within the request object requires a map syntax e.g."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM http;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"clientip"),(0,s.kt)("th",{parentName:"tr",align:"left"},"request"),(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"size"),(0,s.kt)("th",{parentName:"tr",align:"left"},"timestamp"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"45.212.12.0"),(0,s.kt)("td",{parentName:"tr",align:"left"},"{'method':'GET','path':'/french/images/hm","_","nav","_","bar.gif','version':'HTTP/1.1'}"),(0,s.kt)("td",{parentName:"tr",align:"left"},"200"),(0,s.kt)("td",{parentName:"tr",align:"left"},"3305"),(0,s.kt)("td",{parentName:"tr",align:"left"},"1998-06-14 10:11:17")))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT timestamp, request['method'] as method, status FROM http WHERE request['method'] = 'GET';\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"timestamp"),(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"status"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"1998-06-14 10:11:17"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"200")))),(0,s.kt)("p",null,"A full set of map functions is available to query this time, described ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/tuple-map-functions"},"here"),". If your data is not of a consistent type, functions exist to perform the necessary coercion. The following example, exploits the fact that data objects can also be inserted into a map in the structure",(0,s.kt)("inlineCode",{parentName:"p"}," [(key, value), (key, value),...]")," e.g. ",(0,s.kt)("inlineCode",{parentName:"p"},"[('method', 'GET'),('path', '/french/images/hm\\_nav\\_bar.gif'),('version', 'HTTP/1.1')]")),(0,s.kt)("p",null,"This function in turn allows us to insert our full s3 dataset with no need to reformat the data."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http (`@timestamp`, clientip, request,\nstatus, size) SELECT `@timestamp`, clientip, request, status, size FROM\ns3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow');\n")),(0,s.kt)("p",null,"To reproduce our earlier query example which analyzes status codes by HTTP method, we require the use of the map syntax:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT status, request['method'] as method, count() as c\nFROM http\nWHERE status >= 400\n AND timestamp BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status\nORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("h4",{id:"nested-vs-tuple-vs-map"},"Nested vs Tuple vs Map"),(0,s.kt)("p",null,"Each of the above strategies for handling nested JSON has its respective advantages and disadvantages. The following captures these differences."),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"center"},"Type"),(0,s.kt)("th",{parentName:"tr",align:"center"},"Requires custom INSERT format"),(0,s.kt)("th",{parentName:"tr",align:"center"},"Requires custom notation to read fields"),(0,s.kt)("th",{parentName:"tr",align:"center"},"Constraints on structure e.g. list lengths or types"),(0,s.kt)("th",{parentName:"tr",align:"center"},"Object fields can be used for primary/sort keys"),(0,s.kt)("th",{parentName:"tr",align:"center"},"Creates more columns on disk"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"Nested"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes*"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"Tuple"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"Map"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes"),(0,s.kt)("td",{parentName:"tr",align:"center"},"Yes**"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No"),(0,s.kt)("td",{parentName:"tr",align:"center"},"No")))),(0,s.kt)("p",null,"*Nested requires values (represented as arrays) to have the same length\n**Values must be the same type"),(0,s.kt)("h3",{id:"store-as-string"},"Store as String"),(0,s.kt)("p",null,"Handling data using the structured approach described in ",(0,s.kt)("a",{parentName:"p",href:"#handle-as-structured-data"},"Handle as Structured Data"),", is often not viable for those users with dynamic JSON which is either subject to change or for which the schema is not well understood. For absolute flexibility, users can simply store JSON as Strings before using functions to extract fields as required. This represents the extreme opposite to handling JSON as a structured object. This flexibility incurs costs with significant disadvantages - primarily an increase in query syntax complexity as well as degraded performance."),(0,s.kt)("p",null,"Our table schema, in this case, is trivial:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\nCREATE table http_json\n(\n   message String\n\n) ENGINE = MergeTree ORDER BY tuple();\n")),(0,s.kt)("p",null,"Insertion requires us to send each JSON row as a String. Here we use the format ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/interfaces/formats#jsonasstring"},"JSONAsString")," to ensure our object is interpreted."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO http FORMAT JSONAsString\n  {"@timestamp":897819077,"clientip":"45.212.12.0","request":{"method":"GET",\n  "path":"/french/images/hm_nav_bar.gif","version":"HTTP/1.0"},"status":200,"size":3305}\n')),(0,s.kt)("p",null,"To illustrate queries we can insert our sample from s3:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http SELECT * FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONAsString');\n")),(0,s.kt)("p",null,"The below query counts the requests with a status code greater than 200, grouping by http method."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT JSONExtractString(JSONExtractString(message, 'request'), 'method') as method,\n       JSONExtractInt(message, 'status')                                  as status,\n       count()                                                            as count\nFROM http\nWHERE status >= 400\n  AND method == 'GET'\nGROUP BY method, status;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"count"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"11267")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"400"),(0,s.kt)("td",{parentName:"tr",align:"left"},"81")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"160")))),(0,s.kt)("p",null,"Despite using functions to parse the String, this query should still return for the 10m rows in a few seconds. Notice how the functions require both a reference to the String field message and a path in the JSON to extract. Nested paths require functions to be nested  e.g. ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONExtractString(JSONExtractString(message, 'request'), 'method')")," extracts the field ",(0,s.kt)("inlineCode",{parentName:"p"},"request.method"),". The extraction of nested paths can be simplified through the functions ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/json-functions/#json_queryjson-path"},"JSON_QUERY")," AND ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/functions/json-functions/#json_valuejson-path"},"JSON_VALUE")," as shown below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT JSONExtractInt(message, 'status') AS status, JSON_VALUE(message, '$.request.method') as method,\ncount() as c\nFROM http\nWHERE status >= 400\n  AND toDateTime(JSONExtractUInt(message, '@timestamp')) BETWEEN '1998-01-01 00:00:00'\n  AND '1998-06-01 00:00:00'\nGROUP by method, status\nORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"c"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"11267")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"HEAD"),(0,s.kt)("td",{parentName:"tr",align:"left"},"276")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"160")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"POST"),(0,s.kt)("td",{parentName:"tr",align:"left"},"115")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"400"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"81")))),(0,s.kt)("p",null,"Notice the use of an xpath expression here to filter the JSON by method i.e. ",(0,s.kt)("inlineCode",{parentName:"p"},"JSON_VALUE(message, '$.request.method')"),"."),(0,s.kt)("p",null,"String functions are appreciably slower (> 10x) than explicit type conversions with indices. The above queries always require a full table scan and processing of every row. While these queries will still be fast on a small dataset such as this, performance will degrade on larger datasets."),(0,s.kt)("p",null,"The flexibility this approach provides comes at a clear performance and syntax cost. It can, however, be coupled with other approaches where users extract only the explicit fields they need for indices or frequent queries. For further details on this approach, see ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/integrations/data-formats/json/#hybrid-approach-with-materialized-columns"},"Hybrid approach"),"."),(0,s.kt)("h4",{id:"visit-functions"},"Visit Functions"),(0,s.kt)("p",null,"The above examples use the JSON* family of functions. These utilize a full JSON parser based on ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/simdjson/simdjson"},"simdjson"),", that is rigorous in its parsing and will distinguish between the same field nested at different levels. These functions are able to deal with JSON that is syntactically correct but not well-formatted, e.g. double spaces between keys."),(0,s.kt)("p",null,"A faster and more strict set of functions are available. These visitParam* functions offer potentially superior performance, primarily by making strict assumptions as to the structure and format of the JSON. Specifically:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Field names must be constants")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"Consistent encoding of field names e.g. visitParamHas('{\"abc\":\"def\"}', 'abc') = 1, but visitParamHas('{\"","\\","u0061","\\","u0062","\\","u0063\":\"def\"}', 'abc') = 0")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"The field names are unique across all nested structures. No differentiation is made between nesting levels, and matching is indiscriminate. In the event of multiple matching fields, the first occurrence is used.")),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},"No special characters outside of string literals. This includes spaces. The following is invalid and will not parse."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{"@timestamp": 893964617, "clientip": "40.135.0.0", "request": {"method": "GET",\n"path": "/images/hm_bg.jpg", "version": "HTTP/1.0"}, "status": 200, "size": 24736}\n')),(0,s.kt)("p",{parentName:"li"},"  whereas, will parse correctly"),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{"@timestamp":893964617,"clientip":"40.135.0.0","request":{"method":"GET",\n"path":"/images/hm_bg.jpg","version":"HTTP/1.0"},"status":200,"size":24736}\n')))),(0,s.kt)("p",null,"In some circumstances, where performance is critical and your JSON meets the above requirements,  these may be appropriate. An example of the earlier query, re-written to use visitParam functions is shown below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT visitParamExtractUInt(message, 'status')   AS status,\n       visitParamExtractString(message, 'method') as method,\n       count()                                    as c\nFROM http\nWHERE status >= 400\n  AND toDateTime(visitParamExtractUInt(message, '@timestamp')) BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status\nORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"c"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"11267")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"HEAD"),(0,s.kt)("td",{parentName:"tr",align:"left"},"276")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"160")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"POST"),(0,s.kt)("td",{parentName:"tr",align:"left"},"115")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"400"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"81")))),(0,s.kt)("p",null,"Note that these functions are also aliased to simpleJSON* equivalents. The above query can be rewritten to:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT simpleJSONExtractUInt(message, 'status')   AS status,\n       simpleJSONExtractString(message, 'method') as method,\n       count()                                    as c\nFROM http\nWHERE status >= 400\n  AND toDateTime(simpleJSONExtractUInt(message, '@timestamp')) BETWEEN '1998-01-01 00:00:00'\n  AND '1998-06-01 00:00:00'\nGROUP by method, status;\n")),(0,s.kt)("h3",{id:"using-pairwise-arrays"},"Using Pairwise Arrays"),(0,s.kt)("p",null,"Pairwise arrays provide a balance between the flexibility of representing JSON as Strings and the performance of a more structured approach. The schema is flexible in that any new fields can be potentially added to the root. This, however, requires a significantly more complex query syntax and isn\u2019t compatible with nested structures."),(0,s.kt)("p",null,"As an example, consider the following table:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE http_with_arrays (\n   keys Array(String),\n   values Array(String)\n)\nENGINE = MergeTree  ORDER BY tuple();\n")),(0,s.kt)("p",null,"To insert into this table, we need to structure the JSON as a list of keys and values. The following query illustrates the use of the ",(0,s.kt)("inlineCode",{parentName:"p"},"JSONExtractKeysAndValues")," to achieve this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT arrayMap(x -> x.1, JSONExtractKeysAndValues(json, 'String')) as keys,\n       arrayMap(x -> x.2, JSONExtractKeysAndValues(json, 'String')) as values\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONAsString') LIMIT 1;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"keys"),(0,s.kt)("th",{parentName:"tr",align:"left"},"values"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"[","'@timestamp','clientip','request','status','size'","]"),(0,s.kt)("td",{parentName:"tr",align:"left"},"[",'\'893964617\',\'40.135.0.0\',\'{"method":"GET","path":"/images/hm',"_","bg.jpg\",\"version\":\"HTTP/1.0\"}','200','24736'","]")))),(0,s.kt)("p",null,"Note how the request column remains a nested structure represented as a string. We can insert any new keys to the root. We can also have arbitrary differences in the JSON itself. To insert into our local table, execute the following:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http_with_arrays\nSELECT arrayMap(x ->\n                    x.1, JSONExtractKeysAndValues(message, 'String')) keys\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONEachRow');\n")),(0,s.kt)("p",null,"Querying this structure requires using the indexOf function to identify the index of the required key (which should be consistent with the order of the values). This can in turn be used to access the values array column i.e. ",(0,s.kt)("inlineCode",{parentName:"p"},"values[indexOf(keys, 'status')]"),". We still require a JSON parsing method for the request column - in this case, ",(0,s.kt)("inlineCode",{parentName:"p"},"simpleJSONExtractString"),"."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT toUInt16(values[indexOf(keys, 'status')])                           as status,\n       simpleJSONExtractString(values[indexOf(keys, 'request')], 'method') as method,\n       count()                                                             as c\nFROM http_with_arrays\nWHERE status >= 400\n  AND toDateTime(values[indexOf(keys, '@timestamp')]) BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status ORDER BY c DESC LIMIT 5;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"status"),(0,s.kt)("th",{parentName:"tr",align:"left"},"method"),(0,s.kt)("th",{parentName:"tr",align:"left"},"c"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"11267")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"404"),(0,s.kt)("td",{parentName:"tr",align:"left"},"HEAD"),(0,s.kt)("td",{parentName:"tr",align:"left"},"276")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"160")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"500"),(0,s.kt)("td",{parentName:"tr",align:"left"},"POST"),(0,s.kt)("td",{parentName:"tr",align:"left"},"115")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"400"),(0,s.kt)("td",{parentName:"tr",align:"left"},"GET"),(0,s.kt)("td",{parentName:"tr",align:"left"},"81")))),(0,s.kt)("h3",{id:"hybrid-approach-with-materialized-columns"},"Hybrid Approach with Materialized Columns"),(0,s.kt)("p",null,"The approaches outlined above are not either OR. While parsing JSON fields to structured columns offers the best query performance, it also potentially incurs the highest insertion overhead if done in ClickHouse. Practically, it is also sometimes not possible due to dirty or variable data or even potentially an unknown schema. Conversely, keeping the JSON as Strings or using pairwise arrays, while flexible, significantly increases query complexity and makes accessing the data the function of someone with ClickHouse expertise."),(0,s.kt)("p",null,"As a compromise, users can use a hybrid approach: representing the JSON as a String initially, extracting columns as required. While not essential, Materialized Columns can assist with this."),(0,s.kt)("p",null,"For example, maybe we start with the following initial schema:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\n\nCREATE table http\n(\n    message   String,\n    method String DEFAULT JSONExtractString(JSONExtractString(message, 'request'), 'method'),\n    status    UInt16 DEFAULT toUInt16(JSONExtractInt(message, 'status')),\n    size      UInt32 DEFAULT toUInt32(JSONExtractInt(message, 'size')),\n    timestamp DateTime DEFAULT toDateTime(JSONExtractUInt(message, '@timestamp'))\n) ENGINE = MergeTree() ORDER BY (status, timestamp);\n")),(0,s.kt)("p",null,"Here we have simply moved our functions to extract data from the SELECT to DEFAULT values. This is somewhat of an artificial case as our JSON is simple and could, in reality, easily be mapped. Typically the columns extracted would be a small subset of a much larger schema."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http (message) SELECT json as message\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONAsString');\n")),(0,s.kt)("p",null,"At this point we may decide we need to add the column ",(0,s.kt)("inlineCode",{parentName:"p"},"client_ip")," after querying it frequently:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE http ADD COLUMN client_ip IPv4 DEFAULT toIPv4(JSONExtractString(message, 'clientip'));\n")),(0,s.kt)("p",null,"The above change will only be incremental, i.e., the column will not exist for data inserted prior to the change. You can still query this column as it will be computed at SELECT time - although at an additional cost. Merges will also cause this column to be added to newly formed parts. To address this, we can use a ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/alter//#mutations"},"mutation")," to update the existing data:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE http UPDATE client_ip = client_ip WHERE 1 = 1\n")),(0,s.kt)("p",null,"The second call here returns immediately and executes asynchronously. Users can track the progress of the update, which requires rewriting the data on disk, using the ",(0,s.kt)("inlineCode",{parentName:"p"},"system.mutations")," table. Further details ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/alter//#mutations"},"here"),". Note that this is a potentially expensive operation and should be scheduled accordingly. It is, however, more optimal than an ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/optimize"},"OPTIMIZE TABLE <table_name> FINAL")," since it only writes the changed column."),(0,s.kt)("h4",{id:"default-vs-materialized"},"Default vs Materialized"),(0,s.kt)("p",null,"The use of default columns represents one of the ways to achieve \u201cMaterialized columns\u201d. There is also a ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/create/table/#materialized"},"MATERIALIZED")," column syntax. This differs from ",(0,s.kt)("a",{parentName:"p",href:"/docs/en/sql-reference/statements/create/table/#default"},"DEFAULT")," in a few ways:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"MATERIALIZED columns cannot be provided on INSERT i.e. they must always be computed from other columns. Conversely, DEFAULT columns can be optionally provided."),(0,s.kt)("li",{parentName:"ul"},"SELECT * will skip MATERIALIZED columns i.e. they must be specifically requested. This allows a table dump to be reloaded back into a table of the same definition.")),(0,s.kt)("h4",{id:"assessing-storage-usage"},"Assessing Storage Usage"),(0,s.kt)("p",null,"While extracting columns incurs a storage cost, typically, this can be minimized with a careful selection of codecs. Users will often wish to assess the cost of materializing a column prior. This cost only has a storage overhead if not queried - during the column-oriented nature of ClickHouse. We recommend testing the materialization on a subset of the data using a test table. The cost can, in turn, be computed using the following query, which can also provide an estimate of the compression achieved."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT table,\n      name,\n      type,\n      compression_codec,\n      formatReadableSize(data_compressed_bytes)       as compressed_size,\n      formatReadableSize(data_uncompressed_bytes)     as uncompressed_size,\n      data_compressed_bytes / data_uncompressed_bytes as compression_ratio\nFROM system.columns\nWHERE database = currentDatabase()\nORDER BY table, name;\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"left"},"table"),(0,s.kt)("th",{parentName:"tr",align:"left"},"name"),(0,s.kt)("th",{parentName:"tr",align:"left"},"type"),(0,s.kt)("th",{parentName:"tr",align:"left"},"compression","_","codec"),(0,s.kt)("th",{parentName:"tr",align:"left"},"compressed","_","size"),(0,s.kt)("th",{parentName:"tr",align:"left"},"uncompressed","_","size"),(0,s.kt)("th",{parentName:"tr",align:"left"},"compression","_","ratio"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"client","_","ip"),(0,s.kt)("td",{parentName:"tr",align:"left"},"IPv4"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"23.51 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"38.15 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.61624925")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"message"),(0,s.kt)("td",{parentName:"tr",align:"left"},"String"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"203.00 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"1.48 GiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.1336674472634663")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"method"),(0,s.kt)("td",{parentName:"tr",align:"left"},"String"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"363.75 KiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"38.18 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.009304780749750751")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"size"),(0,s.kt)("td",{parentName:"tr",align:"left"},"UInt32"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"24.19 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"38.15 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.6341134")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"status"),(0,s.kt)("td",{parentName:"tr",align:"left"},"UInt16"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"87.49 KiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"19.07 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.00447955")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"left"},"http"),(0,s.kt)("td",{parentName:"tr",align:"left"},"timestamp"),(0,s.kt)("td",{parentName:"tr",align:"left"},"DateTime"),(0,s.kt)("td",{parentName:"tr",align:"left"}),(0,s.kt)("td",{parentName:"tr",align:"left"},"4.98 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"38.15 MiB"),(0,s.kt)("td",{parentName:"tr",align:"left"},"0.1306381")))),(0,s.kt)("h4",{id:"using-materialized-views"},"Using Materialized Views"),(0,s.kt)("p",null,"Using the hybrid approach described above requires significant processing at insertion time. This complicates data insertion logic and potentially introduces fragility in your data ingestion layer. To address this, we can exploit materialized views."),(0,s.kt)("p",null,"The general concept here is to exploit a table with the null engine for receiving inserts. This table engine doesn\u2019t store any data and acts as a \u201cbuffer\u201d for the materialized view only. For each insert block, the materialized view will trigger, perform the processing the required and insert rows into a target table that we can in turn query. In cases where we need to update the schema, extracting a new field from the blob, we simply update our table schema and then modify the materialized view accordingly to extract the field. Our materialized view and null table engine effectively act as an ETL pipeline, as shown below:"),(0,s.kt)("img",{src:a(95629).Z,class:"image",alt:"Working with JSON",style:{width:"100%"}}),(0,s.kt)("p",null,"First we create our null table engine for receiving inserts:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE http_etl (\n   message String\n) ENGINE = Null;\n")),(0,s.kt)("p",null,"Our target MergeTree table has a subset of the fields - ones we are maybe confident will occur in the JSON string. Note we retain a String field message for other data that can be used with JSON* functions if required."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"DROP TABLE IF EXISTS http;\n\nCREATE table http\n(\n    message   String,\n    method String,\n    status    UInt16,\n    size      UInt32,\n    timestamp DateTime\n) ENGINE = MergeTree() ORDER BY (status, timestamp);\n")),(0,s.kt)("p",null,"Our materialized view in turn extracts the fields that have been declared in the http table schema."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE MATERIALIZED VIEW http_mv TO http AS\nSELECT message,\n       JSONExtractString(JSONExtractString(message, 'request'), 'method') as method,\n       toUInt16(JSONExtractInt(message, 'status'))                  as status,\n       toUInt32(JSONExtractInt(message, 'size'))                       as size,\n       toDateTime(JSONExtractUInt(message, '@timestamp')) as timestamp\nFROM http_etl;\n")),(0,s.kt)("p",null,"Using the sample data from our s3 bucket, the insert is simplified to:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO http_etl SELECT json as message FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONAsString');\n")),(0,s.kt)("p",null,"Our analysis of error codes and http methods thus becomes trivial:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT status,\n      method,\n      count() as c\nFROM http\nWHERE status >= 400\n AND timestamp BETWEEN '1998-01-01 00:00:00' AND '1998-06-01 00:00:00'\nGROUP by method, status ORDER BY c DESC;\n")),(0,s.kt)("h4",{id:"updating-materialized-views"},"Updating Materialized Views"),(0,s.kt)("p",null,"Suppose we later wish to extract the field ",(0,s.kt)("inlineCode",{parentName:"p"},"client_ip")," from our JSON blob. First we update our target table."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER TABLE http\n    ADD COLUMN client_ip IPv4;\n")),(0,s.kt)("p",null,"Using the setting ",(0,s.kt)("inlineCode",{parentName:"p"},"allow_experimental_alter_materialized_view_structure")," we can modify our Materialized View:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"SET allow_experimental_alter_materialized_view_structure = 1;\nALTER TABLE http_mv\n   MODIFY QUERY SELECT message,\n   JSONExtractString(JSONExtractString(message, 'request'), 'method') as method,\n   toUInt16(JSONExtractInt(message, 'status')) as status,\n   toUInt32(JSONExtractInt(message, 'size')) as size,\n   toIPv4(JSONExtractString(message, 'clientip')) as client_ip,\n   toDateTime(JSONExtractUInt(message, '@timestamp')) as timestamp\n   FROM http_etl;\n")),(0,s.kt)("p",null,"Note how this feature is experimental. You can alternatively drop the view using ",(0,s.kt)("inlineCode",{parentName:"p"},"DROP VIEW")," and recreate it - however this does require pausing insertions."),(0,s.kt)("p",null,"If an update of the target table is required, see the use of mutations in ",(0,s.kt)("a",{parentName:"p",href:"#hybrid-approach-with-materialized-columns"},"Hybrid Approach"),"."),(0,s.kt)("h4",{id:"using-for-pairwise-arrays"},"Using for Pairwise Arrays"),(0,s.kt)("p",null,"In the above example, we represented fields we wished to frequently query explicitly as columns. A materialized view could also be potentially used to extract pairwise arrays. This shifts potentially expensive logic from the SELECT statement. For example:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE http_with_arrays\n(\n   keys Array(String),\n   values Array(String)\n)\n   ENGINE = MergeTree ORDER BY tuple();\n\nCREATE MATERIALIZED VIEW http_mv TO http_with_arrays AS\nSELECT arrayMap(x -> x.1, JSONExtractKeysAndValues(message, 'String')) as keys,\n      arrayMap(x -> x.2, JSONExtractKeysAndValues(message, 'String')) as values\nFROM http_etl;\n\nINSERT INTO http_etl\nSELECT json as message\nFROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/http/documents-01.ndjson.gz',\n'JSONAsString');\n")),(0,s.kt)("h2",{id:"related-content"},"Related Content"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"https://clickhouse.com/blog/getting-data-into-clickhouse-part-2-json"},"Getting Data Into ClickHouse - Part 2 - A JSON detour"))))}u.isMDXComponent=!0},61268:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/arrays-312007dfdc6340fedc824785b471aab5.json"},11638:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/columns-array-c8efc8e942324c6820ce841d68336180.json"},1996:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/columns-b5f7725e736f41c9f065342a554e79cf.json"},46287:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/custom-aad5c988b86a38da5e95f5d76aa438e6.json"},4670:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/data-fba81c8aea76b4e71c16bcb3b8a6a77a.bson"},76678:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/list-nested-ea2507b8a6fd7aabe23665516cf650e2.json"},19239:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/list-e590894c9dcb14bad20ba201c5806dca.json"},43817:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/object-per-line-915f97178ec782235df704ab5cc9f029.json"},40743:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/files/objects-c065aaa42144df69198a696f6811321b.json"},95629:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/working-with-json_01-6328ea72616206abb644303060a14d6f.png"}}]);
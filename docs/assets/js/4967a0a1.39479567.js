"use strict";(self.webpackChunkclickhouse=self.webpackChunkclickhouse||[]).push([[58740],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return p}});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=a.createContext({}),l=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=l(e.components);return a.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=l(n),p=i,f=m["".concat(c,".").concat(p)]||m[p]||d[p]||r;return n?a.createElement(f,s(s({ref:t},u),{},{components:n})):a.createElement(f,s({ref:t},u))}));function p(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=m;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o.mdxType="string"==typeof e?e:i,s[1]=o;for(var l=2;l<r;l++)s[l]=n[l];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},88346:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return c},default:function(){return p},frontMatter:function(){return o},metadata:function(){return l},toc:function(){return d}});var a=n(87462),i=n(63366),r=(n(67294),n(3905)),s=["components"],o={slug:"/en/manage/tuning-for-cloud-cost-efficiency",sidebar_position:63,sidebar_label:"Tuning for Cloud Cost Efficiency",title:"Tuning for Cloud Cost Efficiency"},c=void 0,l={unversionedId:"en/manage/tuning-for-cloud-cost-efficiency",id:"en/manage/tuning-for-cloud-cost-efficiency",title:"Tuning for Cloud Cost Efficiency",description:"ClickHouse Cloud is using cloud object storage for your data. Write requests to object storage are more expensive than read requests. Here are some tips for minimizing the amount of write requests in ClickHouse Cloud.",source:"@site/docs/en/manage/tuning-for-cloud-cost-efficiency.md",sourceDirName:"en/manage",slug:"/en/manage/tuning-for-cloud-cost-efficiency",permalink:"/docs/en/manage/tuning-for-cloud-cost-efficiency",draft:!1,editUrl:"https://github.com/ClickHouse/clickhouse-docs/blob/main/docs/en/manage/tuning-for-cloud-cost-efficiency.md",tags:[],version:"current",sidebarPosition:63,frontMatter:{slug:"/en/manage/tuning-for-cloud-cost-efficiency",sidebar_position:63,sidebar_label:"Tuning for Cloud Cost Efficiency",title:"Tuning for Cloud Cost Efficiency"},sidebar:"english",previous:{title:"Monitoring",permalink:"/docs/en/operations/monitoring"},next:{title:"Replication and Sharding",permalink:"/docs/en/manage/replication-and-sharding"}},u={},d=[{value:"Ingest data in bulk",id:"ingest-data-in-bulk",level:2},{value:"Use asynchronous inserts",id:"use-asynchronous-inserts",level:2},{value:"Avoid mutations",id:"avoid-mutations",level:2},{value:"Avoid using OPTIMIZE FINAL",id:"avoid-using-optimize-final",level:2},{value:"Avoid using Nullable column",id:"avoid-using-nullable-column",level:2}],m={toc:d};function p(e){var t=e.components,o=(0,i.Z)(e,s);return(0,r.kt)("wrapper",(0,a.Z)({},m,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"ClickHouse Cloud is using cloud object storage for your data. Write requests to object storage are more expensive than read requests. Here are some tips for minimizing the amount of write requests in ClickHouse Cloud."),(0,r.kt)("h2",{id:"ingest-data-in-bulk"},"Ingest data in bulk"),(0,r.kt)("p",null,"By default, each insert sent to ClickHouse causes ClickHouse to immediately create a part on storage containing the data from the insert together with other metadata that needs to be stored.\nTherefore sending a smaller amount of inserts that each contain more data, compared to sending a larger amount of inserts that each contain less data, will reduce the number of writes required. Generally, we recommend inserting data in fairly large batches of at least 1,000 rows at a time, and ideally between 10,000 to 100,000 rows. To achieve this, consider implementing a buffer mechanism such as using Kafka in your application to enable batch inserts, or use asynchronous inserts (see ",(0,r.kt)("a",{parentName:"p",href:"#insert-data-asynchronously"},"next section"),")."),(0,r.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"tip")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Regardless of the size of your inserts, we recommend to keep the number of insert queries around one insert query per second.\nThe reason for that recommendation is that the created parts are merged to larger parts in the background (in order to optimize your data for read queries), and sending too many insert queries per second can lead to situations where the background merging can't keep up with the amount of new parts.\nHowever, you can use a higher rate of insert queries per second when you use asynchronous inserts (see ",(0,r.kt)("a",{parentName:"p",href:"#insert-data-asynchronously"},"next section"),")."))),(0,r.kt)("h2",{id:"use-asynchronous-inserts"},"Use asynchronous inserts"),(0,r.kt)("p",null,"Use ",(0,r.kt)("a",{parentName:"p",href:"https://clickhouse.com/blog/click-house-v2111-released"},"asynchronous inserts")," as an alternative to both batching data on the client-side and keeping the insert rate at around one insert query per second by enabling the ",(0,r.kt)("a",{parentName:"p",href:"../operations/settings/settings/#async-insert"},"async_insert")," setting. This causes ClickHouse to handle the batching on the server-side. Doing so will therefore reduce the number of write requests generated."),(0,r.kt)("p",null,"As mentioned in the previous section, by default, ClickHouse is writing data synchronously.\nEach insert sent to ClickHouse causes ClickHouse to immediately create a part containing the data from the insert.\nThis is the default behavior when the async_insert setting is set to its default value of 0:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"compression block diagram",src:n(3361).Z,width:"2659",height:"1996"})),(0,r.kt)("p",null,"By setting async_insert to 1, ClickHouse first stores the incoming inserts into an in-memory buffer before flushing them regularly to disk. This asynchronous behavior allows ClickHouse to automatically batch your data up to 100KB (configurable via ",(0,r.kt)("a",{parentName:"p",href:"../operations/settings/settings/#async-insert-max-data-size"},"async_insert_max_data_size"),") or wait for 200ms (since the first insert) (configurable via ",(0,r.kt)("a",{parentName:"p",href:"../operations/settings/settings/#async-insert-max-data-size"},"async_insert_busy_timeout_ms"),") before writing the data to a new part in the object storage. This helps to reduce the amount of write requests for frequent inserts."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Your data is available for read queries once the data is written to a part on storage.\nKeep that in mind, when you want to modify the async_insert_busy_timeout_ms (default value:  200ms) or the async_insert_max_data_size (default value: 100KB) settings."))),(0,r.kt)("p",null,"With the ",(0,r.kt)("a",{parentName:"p",href:"../operations/settings/settings/#wait-for-async-insert"},"wait_for_async_insert")," setting, you can configure if you want an insert statement to return with an acknowledgment either immediately after the data got inserted into the buffer (wait_for_async_insert = 0) or by default, after the data got written to a part after flushing from buffer (wait_for_async_insert = 1). "),(0,r.kt)("p",null,"The following two diagrams illustrate the two settings for async_insert and wait_for_async_insert:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"compression block diagram",src:n(13083).Z,width:"3564",height:"2117"})),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"compression block diagram",src:n(76097).Z,width:"3574",height:"2100"})),(0,r.kt)("p",null,"You can specify the asynchronous insert settings by using the SETTINGS clause of insert queries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO YourTable SETTINGS async_insert=1, wait_for_async_insert=0 VALUES (...)\n")),(0,r.kt)("p",null,"You can also specify asynchronous insert settings as connection parameters when using a ClickHouse programming language client.\nAs an example, this is how you can do that within a JDBC connection string when you use the ClickHouse Java JDBC driver for connecting to ClickHouse Cloud :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'"jdbc:ch://HOST.clickhouse.cloud:8443/?user=default&password=PASSWORD&ssl=true&custom_http_params=async_insert=1,wait_for_async_insert=0"\n')),(0,r.kt)("h2",{id:"avoid-mutations"},"Avoid mutations"),(0,r.kt)("p",null,"Mutations refers to ",(0,r.kt)("a",{parentName:"p",href:"../sql-reference/statements/alter/"},"ALTER")," queries that manipulate table data through deletion or updates. Most notably they are queries like ALTER TABLE \u2026 DELETE, UPDATE, etc. Performing such queries will produce new mutated versions of the data parts. This means that such statements would trigger a rewrite of whole data parts for all data that was inserted before the mutation, translating to a large amount of write requests."),(0,r.kt)("p",null,"For updates you can avoid such large amount of write requests by using spezialised table engines like ",(0,r.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replacingmergetree/"},"ReplacingMergeTree")," or ",(0,r.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/collapsingmergetree"},"CollapsingMergeTree")," instead of the default MergeTree table engine."),(0,r.kt)("h2",{id:"avoid-using-optimize-final"},"Avoid using OPTIMIZE FINAL"),(0,r.kt)("p",null,"Using the ",(0,r.kt)("a",{parentName:"p",href:"../sql-reference/statements/optimize/"},"OPTIMIZE TABLE ... FINAL")," query will initiate an unscheduled merge of data parts for the specific table into one data part. During this process, ClickHouse reads all the data parts, uncompresses, merges, compresses them into a single part, and then rewrites back into object store, causing huge CPU and IO consumption. Note that this optimization rewrites the one part even if they are already merged into a single part."),(0,r.kt)("h2",{id:"avoid-using-nullable-column"},"Avoid using Nullable column"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"../sql-reference/data-types/nullable/"},"Nullable column")," (e.g. Nullable(UInt8)) creates a separate column of UInt8 type. This additional column has to be processed every time when user works with a nullable column. This leads to an additional storage space used and almost always negatively affects performance."))}p.isMDXComponent=!0},3361:function(e,t,n){t.Z=n.p+"assets/images/async-01-83309328e1c750b0da51c86692b85f74.png"},13083:function(e,t,n){t.Z=n.p+"assets/images/async-02-e01d1ed7002ee59d3287befd33f0cff7.png"},76097:function(e,t,n){t.Z=n.p+"assets/images/async-03-4f1ae9dae0e06c26b5363b2e12535d6c.png"}}]);